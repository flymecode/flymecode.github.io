<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小白君的博客</title>
  
  <subtitle>凡事必先骑上虎背</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-08-13T15:58:28.445Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Ma Xu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>MESI</title>
    <link href="http://yoursite.com/2019/08/13/MESI/"/>
    <id>http://yoursite.com/2019/08/13/MESI/</id>
    <published>2019-08-13T15:19:17.000Z</published>
    <updated>2019-08-13T15:58:28.445Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CPU缓存一致性协议MESI"><a href="#CPU缓存一致性协议MESI" class="headerlink" title="CPU缓存一致性协议MESI"></a>CPU缓存一致性协议MESI</h1><h2 id="CPU高速缓存（Cache-Memory）"><a href="#CPU高速缓存（Cache-Memory）" class="headerlink" title="CPU高速缓存（Cache Memory）"></a>CPU高速缓存（Cache Memory）</h2><h3 id="CPU为何要有高速缓存"><a href="#CPU为何要有高速缓存" class="headerlink" title="CPU为何要有高速缓存"></a>CPU为何要有高速缓存</h3><p>CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。</p><p>在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。</p><blockquote><p><strong>时间局部性（Temporal Locality）</strong>：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。</p></blockquote><p>比如循环、递归、方法的反复调用等。</p><blockquote><p><strong>空间局部性（Spatial Locality）</strong>：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。</p></blockquote><p>比如顺序执行的代码、连续创建的两个对象、数组等。</p><a id="more"></a><h3 id="带有高速缓存的CPU执行计算的流程"><a href="#带有高速缓存的CPU执行计算的流程" class="headerlink" title="带有高速缓存的CPU执行计算的流程"></a>带有高速缓存的CPU执行计算的流程</h3><ol><li>程序以及数据被加载到主内存</li><li>指令和数据被加载到CPU的高速缓存</li><li>CPU执行指令，把结果写到高速缓存</li><li>高速缓存中的数据写回主内存</li></ol><p><img src="/2019/08/13/MESI/WX20190813-233303@2x.png" alt></p><h3 id="目前流行的多级缓存结构"><a href="#目前流行的多级缓存结构" class="headerlink" title="目前流行的多级缓存结构"></a>目前流行的多级缓存结构</h3><p>由于CPU的运算速度超越了1级缓存的数据I\O能力，CPU厂商又引入了多级的缓存结构。</p><p>多级缓存结构</p><p><img src="/2019/08/13/MESI/WX20190813-233623@2x.png" alt></p><h2 id="多核CPU多级缓存一致性协议MESI"><a href="#多核CPU多级缓存一致性协议MESI" class="headerlink" title="多核CPU多级缓存一致性协议MESI"></a>多核CPU多级缓存一致性协议MESI</h2><p>多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。</p><h3 id="MESI协议缓存状态"><a href="#MESI协议缓存状态" class="headerlink" title="MESI协议缓存状态"></a>MESI协议缓存状态</h3><p>MESI 是指4中状态的首字母。每个Cache line有4个状态，可用2个bit表示，它们分别是：</p><blockquote><p><strong>缓存行（Cache line）</strong>:缓存存储数据的单元。</p></blockquote><table><thead><tr><th style="text-align:left">状态</th><th style="text-align:left">描述</th><th style="text-align:left">监听任务</th></tr></thead><tbody><tr><td style="text-align:left">M 修改 (Modified)</td><td style="text-align:left">该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。</td><td style="text-align:left">缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。</td></tr><tr><td style="text-align:left">E 独享、互斥 (Exclusive)</td><td style="text-align:left">该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。</td><td style="text-align:left">缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。</td></tr><tr><td style="text-align:left">S 共享 (Shared)</td><td style="text-align:left">该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。</td><td style="text-align:left">缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。</td></tr><tr><td style="text-align:left">I 无效 (Invalid)</td><td style="text-align:left">该Cache line无效。</td><td style="text-align:left">无</td></tr></tbody></table><p><strong>注意：</strong><br><strong>对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的，而S状态可能是非一致的</strong>。如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其它缓存不会广播他们作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行。</p><p>从上面的意义看来E状态是一种投机性的优化：如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务</p><h3 id="MESI状态转换"><a href="#MESI状态转换" class="headerlink" title="MESI状态转换"></a>MESI状态转换</h3><p><img src="/2019/08/13/MESI/WX20190813-234607@2x.png" alt></p><p>理解该图的前置说明：<br>1.触发事件</p><table><thead><tr><th style="text-align:left">触发事件</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">本地读取（Local read）</td><td style="text-align:left">本地cache读取本地cache数据</td></tr><tr><td style="text-align:left">本地写入（Local write）</td><td style="text-align:left">本地cache写入本地cache数据</td></tr><tr><td style="text-align:left">远端读取（Remote read）</td><td style="text-align:left">其他cache读取本地cache数据</td></tr><tr><td style="text-align:left">远端写入（Remote write）</td><td style="text-align:left">其他cache写入本地cache数据</td></tr></tbody></table><p>2.cache分类：<br>前提：所有的cache共同缓存了主内存中的某一条数据。</p><p>本地cache:指当前cpu的cache。<br>触发cache:触发读写事件的cache。<br>其他cache:指既除了以上两种之外的cache。<br>注意：本地的事件触发 本地cache和触发cache为相同。</p><p>上图的切换解释：</p><table><thead><tr><th style="text-align:center">状态</th><th style="text-align:center">触发本地读取</th><th style="text-align:center">触发本地写入</th><th style="text-align:center">触发远端读取</th><th style="text-align:center">触发远端写入</th></tr></thead><tbody><tr><td style="text-align:center"><strong>M状态（修改）</strong></td><td style="text-align:center">本地cache:M  触发cache:M 其他cache:I</td><td style="text-align:center">本地cache:M  触发cache:M 其他cache:I</td><td style="text-align:center">本地cache:M→E→S 触发cache:I→S 其他cache:I→S 同步主内存后修改为E独享,同步触发、其他cache后本地、触发、其他cache修改为S共享</td><td style="text-align:center">本地cache:M→E→S→I 触发cache:I→S→E→M 其他cache:I→S→I 同步和读取一样,同步完成后触发cache改为M，本地、其他cache改为I</td></tr><tr><td style="text-align:center"><strong>E状态（独享）</strong></td><td style="text-align:center">本地cache:E 触发cache:E 其他cache:I</td><td style="text-align:center">本地cache:E→M 触发cache:E→M 其他cache:I 本地cache变更为M,其他cache状态应当是I（无效）</td><td style="text-align:center">本地cache:E→S 触发cache:I→S 其他cache:I→S 当其他cache要读取该数据时，其他、触发、本地cache都被设置为S(共享)</td><td style="text-align:center">本地cache:E→S→I 触发cache:I→S→E→M 其他cache:I→S→I 当触发cache修改本地cache独享数据时时，将本地、触发、其他cache修改为S共享.然后触发cache修改为独享，其他、本地cache修改为I（无效），触发cache再修改为M</td></tr><tr><td style="text-align:center"><strong>S状态(共享)</strong></td><td style="text-align:center">本地cache:S 触发cache:S 其他cache:S</td><td style="text-align:center">本地cache:S→E→M 触发cache:S→E→M 其他cache:S→I  当本地cache修改时，将本地cache修改为E,其他cache修改为I,然后再将本地cache为M状态</td><td style="text-align:center">本地cache:S 触发cache:S 其他cache:S</td><td style="text-align:center">本地cache:S→I 触发cache：S→E→M 其他cache:S→I 当触发cache要修改本地共享数据时，触发cache修改为E（独享）,本地、其他cache修改为I（无效）,触发cache再次修改为M(修改)</td></tr><tr><td style="text-align:center"><strong>I状态（无效）</strong></td><td style="text-align:center">本地cache:I→S或者I→E 触发cache:I→S或者I →E 其他cache:E、M、I→S、I 本地、触发cache将从I无效修改为S共享或者E独享，其他cache将从E、M、I 变为S或者I</td><td style="text-align:center">本地cache:I→S→E→M 触发cache:I→S→E→M 其他cache:M、E、S→S→I</td><td style="text-align:center">既然是本cache是I，其他cache操作与它无关</td><td style="text-align:center">既然是本cache是I，其他cache操作与它无关</td></tr></tbody></table><p>下图示意了，当一个cache line的调整的状态的时候，另外一个cache line 需要调整的状态。</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">M</th><th style="text-align:center">E</th><th style="text-align:center">S</th><th style="text-align:center"><strong>I</strong></th></tr></thead><tbody><tr><td style="text-align:center"><strong>M</strong></td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center"><strong>E</strong></td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center"><strong>S</strong></td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center"><strong>I</strong></td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr></tbody></table><p>举个栗子来说：</p><p>假设cache 1 中有一个变量x = 0的cache line 处于S状态(共享)。<br>那么其他拥有x变量的cache 2、cache 3等x的cache line调整为S状态（共享）或者调整为 I 状态（无效）。</p><h3 id="多核缓存协同操作"><a href="#多核缓存协同操作" class="headerlink" title="多核缓存协同操作"></a>多核缓存协同操作</h3><p>假设有三个CPU A、B、C，对应三个缓存分别是cache a、b、 c。在主内存中定义了x的引用值为0。</p><p><img src="/2019/08/13/MESI/WX20190813-235111@2x.png" alt></p><h4 id="单核读取"><a href="#单核读取" class="headerlink" title="单核读取"></a>单核读取</h4><p>那么执行流程是：<br>CPU A发出了一条指令，从主内存中读取x。<br>从主内存通过bus读取到缓存中（远端读取Remote read）,这是该Cache line修改为E状态（独享）.</p><p><img src="/2019/08/13/MESI/WX20190813-235133@2x.png" alt></p><h4 id="双核读取"><a href="#双核读取" class="headerlink" title="双核读取"></a>双核读取</h4><p>那么执行流程是：<br>CPU A发出了一条指令，从主内存中读取x。<br>CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。<br>CPU B发出了一条指令，从主内存中读取x。<br>CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。</p><p><img src="/2019/08/13/MESI/WX20190813-235225@2x.png" alt></p><h4 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h4><p>那么执行流程是：<br>CPU A 计算完成后发指令需要修改x.<br>CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)<br>CPU A 对x进行赋值。</p><p><img src="/2019/08/13/MESI/WX20190813-235306@2x.png" alt></p><h4 id="同步数据"><a href="#同步数据" class="headerlink" title="同步数据"></a>同步数据</h4><p>那么执行流程是：</p><p>CPU B 发出了要读取x的指令。<br>CPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）<br>CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）。</p><p><img src="/2019/08/13/MESI/WX20190813-235340@2x.png" alt></p><h2 id="MESI优化和他们引入的问题"><a href="#MESI优化和他们引入的问题" class="headerlink" title="MESI优化和他们引入的问题"></a>MESI优化和他们引入的问题</h2><p>缓存的一致性消息传递是要时间的，这就使其切换时会产生延迟。当一个缓存被切换状态时其他缓存收到消息完成各自的切换并且发出回应消息这么一长串的时间中CPU都会等待所有缓存响应完成。可能出现的阻塞都会导致各种各样的性能问题和稳定性问题。</p><h3 id="CPU切换状态阻塞解决-存储缓存（Store-Bufferes）"><a href="#CPU切换状态阻塞解决-存储缓存（Store-Bufferes）" class="headerlink" title="CPU切换状态阻塞解决-存储缓存（Store Bufferes）"></a>CPU切换状态阻塞解决-存储缓存（Store Bufferes）</h3><p>比如你需要修改本地缓存中的一条信息，那么你必须将I（无效）状态通知到其他拥有该缓存数据的CPU缓存中，并且等待确认。等待确认的过程会阻塞处理器，这会降低处理器的性能。应为这个等待远远比一个指令的执行时间长的多。</p><h4 id="Store-Bufferes"><a href="#Store-Bufferes" class="headerlink" title="Store Bufferes"></a>Store Bufferes</h4><p>为了避免这种CPU运算能力的浪费，Store Bufferes被引入使用。处理器把它想要写入到主存的值写到缓存，然后继续去处理其他事情。当所有失效确认（Invalidate Acknowledge）都接收到时，数据才会最终被提交。<br>这么做有两个风险</p><h4 id="Store-Bufferes的风险"><a href="#Store-Bufferes的风险" class="headerlink" title="Store Bufferes的风险"></a>Store Bufferes的风险</h4><p>第一、就是处理器会尝试从存储缓存（Store buffer）中读取值，但它还没有进行提交。这个的解决方案称为Store Forwarding，它使得加载的时候，如果存储缓存中存在，则进行返回。<br>第二、保存什么时候会完成，这个并没有任何保证。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">value = <span class="number">3</span>；</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">exeToCPUA</span><span class="params">()</span></span>&#123;</span><br><span class="line">  value = <span class="number">10</span>;</span><br><span class="line">  isFinsh = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">exeToCPUB</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(isFinsh)&#123;</span><br><span class="line">    <span class="comment">//value一定等于10？！</span></span><br><span class="line">    <span class="keyword">assert</span> value == <span class="number">10</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>试想一下开始执行时，CPU A保存着finished在E(独享)状态，而value并没有保存在它的缓存中。（例如，Invalid）。在这种情况下，value会比finished更迟地抛弃存储缓存。完全有可能CPU B读取finished的值为true，而value的值不等于10。</p><p><strong>即isFinsh的赋值在value赋值之前。</strong></p><p>这种在可识别的行为中发生的变化称为重排序（reordings）。注意，这不意味着你的指令的位置被恶意（或者好意）地更改。</p><p>它只是意味着其他的CPU会读到跟程序中写入的顺序不一样的结果。</p><p><del>顺便提一下NIO的设计和Store Bufferes的设计是非常相像的。</del></p><h3 id="硬件内存模型"><a href="#硬件内存模型" class="headerlink" title="硬件内存模型"></a>硬件内存模型</h3><p>执行失效也不是一个简单的操作，它需要处理器去处理。另外，存储缓存（Store Buffers）并不是无穷大的，所以处理器有时需要等待失效确认的返回。这两个操作都会使得性能大幅降低。为了应付这种情况，引入了失效队列。它们的约定如下：</p><ul><li>对于所有的收到的Invalidate请求，Invalidate Acknowlege消息必须立刻发送</li><li>Invalidate并不真正执行，而是被放在一个特殊的队列中，在方便的时候才会去执行。</li><li>处理器不会发送任何消息给所处理的缓存条目，直到它处理Invalidate。</li></ul><p>即便是这样处理器已然不知道什么时候优化是允许的，而什么时候并不允许。<br>干脆处理器将这个任务丢给了写代码的人。这就是内存屏障（Memory Barriers）。</p><blockquote><p><strong>写屏障 Store Memory Barrier(a.k.a. ST, SMB, smp_wmb)是一条告诉处理器在执行这之后的指令之前，应用所有已经在存储缓存（store buffer）中的保存的指令。</strong></p></blockquote><blockquote><p><strong>读屏障Load Memory Barrier (a.k.a. LD, RMB, smp_rmb)是一条告诉处理器在执行任何的加载前，先应用所有已经在失效队列中的失效操作的指令。</strong></p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">executedOnCpu0</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    value = <span class="number">10</span>;</span><br><span class="line">    <span class="comment">//在更新数据之前必须将所有存储缓存（store buffer）中的指令执行完毕。</span></span><br><span class="line">    storeMemoryBarrier();</span><br><span class="line">    finished = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">executedOnCpu1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(!finished);</span><br><span class="line">    <span class="comment">//在读取之前将所有失效队列中关于该数据的指令执行完毕。</span></span><br><span class="line">    loadMemoryBarrier();</span><br><span class="line">    <span class="keyword">assert</span> value == <span class="number">10</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在确实安全了。完美无暇！</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>然而，对于程序员来说简直是一个灾难。不想和平台耦合我们要跨平台。Write One,Run Everywhere!<br>幸好java解决了这个问题，至于如何解决的请关注JMM(JavaMemoryMode)与物理内存相爱相杀。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;CPU缓存一致性协议MESI&quot;&gt;&lt;a href=&quot;#CPU缓存一致性协议MESI&quot; class=&quot;headerlink&quot; title=&quot;CPU缓存一致性协议MESI&quot;&gt;&lt;/a&gt;CPU缓存一致性协议MESI&lt;/h1&gt;&lt;h2 id=&quot;CPU高速缓存（Cache-Memory）&quot;&gt;&lt;a href=&quot;#CPU高速缓存（Cache-Memory）&quot; class=&quot;headerlink&quot; title=&quot;CPU高速缓存（Cache Memory）&quot;&gt;&lt;/a&gt;CPU高速缓存（Cache Memory）&lt;/h2&gt;&lt;h3 id=&quot;CPU为何要有高速缓存&quot;&gt;&lt;a href=&quot;#CPU为何要有高速缓存&quot; class=&quot;headerlink&quot; title=&quot;CPU为何要有高速缓存&quot;&gt;&lt;/a&gt;CPU为何要有高速缓存&lt;/h3&gt;&lt;p&gt;CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。&lt;/p&gt;
&lt;p&gt;在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;时间局部性（Temporal Locality）&lt;/strong&gt;：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比如循环、递归、方法的反复调用等。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;空间局部性（Spatial Locality）&lt;/strong&gt;：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比如顺序执行的代码、连续创建的两个对象、数组等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="缓存" scheme="http://yoursite.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务</title>
    <link href="http://yoursite.com/2019/08/13/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://yoursite.com/2019/08/13/分布式事务/</id>
    <published>2019-08-13T14:12:15.000Z</published>
    <updated>2019-08-13T14:13:59.438Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><p>指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。</p><p>例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。</p><h2 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h2><p>两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。</p><h3 id="1-运行过程"><a href="#1-运行过程" class="headerlink" title="1. 运行过程"></a>1. 运行过程</h3><h4 id="1-1-准备阶段"><a href="#1-1-准备阶段" class="headerlink" title="1.1 准备阶段"></a>1.1 准备阶段</h4><p>协调者询问参与者事务是否执行成功，参与者发回事务执行结果。</p><p><a href="https://camo.githubusercontent.com/0fb5844101fb14358fb16e1acd74604713a9bbf5/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34346433333634332d313030342d343361332d623939612d3464363838613038643061312e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/0fb5844101fb14358fb16e1acd74604713a9bbf5/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34346433333634332d313030342d343361332d623939612d3464363838613038643061312e706e67" alt="img"></a></p><h4 id="1-2-提交阶段"><a href="#1-2-提交阶段" class="headerlink" title="1.2 提交阶段"></a>1.2 提交阶段</h4><p>如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。</p><p>需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。</p><p><a href="https://camo.githubusercontent.com/35c4cbcf56393e07b7e469c671a148f0f4130afe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64326165393933322d653262312d343139312d386565392d6535373366333664333839352e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/35c4cbcf56393e07b7e469c671a148f0f4130afe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64326165393933322d653262312d343139312d386565392d6535373366333664333839352e706e67" alt="img"></a></p><h3 id="2-存在的问题"><a href="#2-存在的问题" class="headerlink" title="2. 存在的问题"></a>2. 存在的问题</h3><h4 id="2-1-同步阻塞"><a href="#2-1-同步阻塞" class="headerlink" title="2.1 同步阻塞"></a>2.1 同步阻塞</h4><p>所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。</p><h4 id="2-2-单点问题"><a href="#2-2-单点问题" class="headerlink" title="2.2 单点问题"></a>2.2 单点问题</h4><p>协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待，无法完成其它操作。</p><h4 id="2-3-数据不一致"><a href="#2-3-数据不一致" class="headerlink" title="2.3 数据不一致"></a>2.3 数据不一致</h4><p>在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。</p><h4 id="2-4-太过保守"><a href="#2-4-太过保守" class="headerlink" title="2.4 太过保守"></a>2.4 太过保守</h4><p>任意一个节点失败就会导致整个事务失败，没有完善的容错机制。</p><h2 id="本地消息表"><a href="#本地消息表" class="headerlink" title="本地消息表"></a>本地消息表</h2><p>本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。</p><ol><li>在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。</li><li>之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。</li><li>在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。</li></ol><p><a href="https://camo.githubusercontent.com/a0b613a1f60db10d1ff1b24810c2ecea4a92d200/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34373633323964342d653265662d346637622d386163392d6135326136663738343630302e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/a0b613a1f60db10d1ff1b24810c2ecea4a92d200/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34373633323964342d653265662d346637622d386163392d6135326136663738343630302e706e67" alt="img"></a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;分布式事务&quot;&gt;&lt;a href=&quot;#分布式事务&quot; class=&quot;headerlink&quot; title=&quot;分布式事务&quot;&gt;&lt;/a&gt;分布式事务&lt;/h1&gt;&lt;p&gt;指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。&lt;/p&gt;
&lt;p&gt;例如在下单场景下，库存和订单如果不在同
      
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>redis实现分布式锁</title>
    <link href="http://yoursite.com/2019/08/13/redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://yoursite.com/2019/08/13/redis实现分布式锁/</id>
    <published>2019-08-13T13:54:48.000Z</published>
    <updated>2019-08-13T14:08:13.760Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-单机Redis实现分布式锁"><a href="#1-单机Redis实现分布式锁" class="headerlink" title="1.单机Redis实现分布式锁"></a>1.单机Redis实现分布式锁</h2><h3 id="1-1获取锁"><a href="#1-1获取锁" class="headerlink" title="1.1获取锁"></a>1.1获取锁</h3><p>获取锁的过程很简单，客户端向Redis发送命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET resource_name my_random_value NX PX 30000</span><br></pre></td></tr></table></figure><p><code>my_random_value</code>是由客户端生成的一个随机字符串，它要保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。 NX表示只有当<code>resource_name</code>对应的key值不存在的时候才能SET成功。这保证了只有第一个请求的客户端才能获得锁，而其它客户端在锁被释放之前都无法获得锁。 PX 30000表示这个锁有一个30秒的自动过期时间。</p><h3 id="1-2-释放锁"><a href="#1-2-释放锁" class="headerlink" title="1.2 释放锁"></a>1.2 释放锁</h3><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">"get"</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">"del"</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>之前获取锁的时候生成的<code>my_random_value</code>作为参数传到Lua脚本里面，作为：<code>ARGV[1]</code>,而 <code>resource_name</code>作为<code>KEYS[1]</code>。Lua脚本可以保证操作的原子性。</p><h3 id="1-3-关于单点Redis实现分布式锁的讨论"><a href="#1-3-关于单点Redis实现分布式锁的讨论" class="headerlink" title="1.3 关于单点Redis实现分布式锁的讨论"></a>1.3 关于单点Redis实现分布式锁的讨论</h3><p>网络上有文章说用如下命令获取锁:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SETNX resource_name my_random_value</span><br><span class="line">EXPIRE resource_name 30</span><br></pre></td></tr></table></figure><p>由于这两个命令不是原子的。如果客户端在执行完<code>SETNX</code>后<code>crash</code>了，那么就没有机会执行<code>EXPIRE</code>了，导致它一直持有这个锁，其他的客户端就永远获取不到这个锁了。</p><ul><li>为什么<code>my_random_value</code>要设置成随机值? 保证了一个客户端释放的锁是自己持有的那个锁。如若不然，可能出现锁不安全的情况。</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">客户端1获取锁成功。</span><br><span class="line">客户端1在某个操作上阻塞了很长时间。</span><br><span class="line">过期时间到了，锁自动释放了。</span><br><span class="line">客户端2获取到了对应同一个资源的锁。</span><br><span class="line">客户端1从阻塞中恢复过来，释放掉了客户端2持有的锁。</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><ul><li>用 SETNX获取锁 网上大量文章说用如下命令获取锁：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETNX lock.foo &lt;current Unix time + lock timeout + 1&gt;</span><br></pre></td></tr></table></figure><p>原文在Redis对SETNX的官网说明，Redis官网文档建议用Set命令来代替，主要原因是SETNX不支持超时时间的设置。</p><p>在开发中 RedisTemplate 为我们封装了 Set 命令</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 如果key不存在，set key and expire key</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> expire</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">setAndExpireIfAbsent</span><span class="params">(<span class="keyword">final</span> String key, <span class="keyword">final</span> Serializable value, <span class="keyword">final</span> <span class="keyword">long</span> expire)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">       Boolean result = (Boolean) RedisTemplateHolder.execute(<span class="keyword">new</span> Statement() &#123;</span><br><span class="line">           <span class="meta">@Override</span></span><br><span class="line">           <span class="function"><span class="keyword">public</span> Object <span class="title">prepare</span><span class="params">(RedisTemplate redisTemplate)</span> </span>&#123;</span><br><span class="line">               <span class="keyword">return</span> redisTemplate.execute(<span class="keyword">new</span> RedisCallback&lt;Boolean&gt;() &#123;</span><br><span class="line">                   <span class="meta">@Override</span></span><br><span class="line">                   <span class="function"><span class="keyword">public</span> Boolean <span class="title">doInRedis</span><span class="params">(RedisConnection connection)</span> <span class="keyword">throws</span> DataAccessException </span>&#123;</span><br><span class="line">                       Object obj = connection.execute(<span class="string">"set"</span>, serialize(key), serialize(value), SafeEncoder.encode(<span class="string">"NX"</span>), SafeEncoder.encode(<span class="string">"EX"</span>), Protocol.toByteArray(expire));</span><br><span class="line">                       <span class="keyword">return</span> obj != <span class="keyword">null</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;, redisTemplate);</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> result;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h2 id="2-Redis集群实现分布式锁"><a href="#2-Redis集群实现分布式锁" class="headerlink" title="2.Redis集群实现分布式锁"></a>2.Redis集群实现分布式锁</h2><p>上面的讨论中我们有一个非常重要的假设：Redis是单点的。如果Redis是集群模式，我们考虑如下场景:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">客户端1从Master获取了锁。</span><br><span class="line">Master宕机了，存储锁的key还没有来得及同步到Slave上。</span><br><span class="line">Slave升级为Master。</span><br><span class="line">客户端2从新的Master获取到了对应同一个资源的锁。</span><br><span class="line">客户端1和客户端2同时持有了同一个资源的锁，锁不再具有安全性。</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><p>就此问题，Redis作者antirez写了RedLock算法来解决这种问题。</p><h3 id="2-1-RedLock获取锁"><a href="#2-1-RedLock获取锁" class="headerlink" title="2.1 RedLock获取锁"></a>2.1 RedLock获取锁</h3><ul><li>获取当前时间。</li><li>按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。</li><li>计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。</li><li>如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。</li><li>如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的单机Redis Lua脚本释放锁的方法）。</li></ul><h3 id="2-2-RedLock释放锁"><a href="#2-2-RedLock释放锁" class="headerlink" title="2.2 RedLock释放锁"></a>2.2 RedLock释放锁</h3><p>客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁的时候成功与否。</p><h3 id="2-3-关于RedLock的问题讨论"><a href="#2-3-关于RedLock的问题讨论" class="headerlink" title="2.3 关于RedLock的问题讨论"></a>2.3 关于RedLock的问题讨论</h3><ul><li>如果有节点发生崩溃重启 假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。</span><br><span class="line">节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。</span><br><span class="line">节点C重启后，客户端2锁住了C, D, E，获取锁成功。</span><br><span class="line">客户端1和客户端2同时获得了锁。</span><br></pre></td></tr></table></figure><p>为了应对这一问题，antirez又提出了延迟重启(delayed restarts)的概念。也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。</p><ul><li>如果客户端长期阻塞导致锁过期</li></ul><p><img src="/2019/08/13/redis实现分布式锁/Users/maxu/hexo/source/_posts/redis实现分布式锁/WX20190813-220656@2x.png" alt></p><p>解释一下这个时序图，客户端1在获得锁之后发生了很长时间的GC pause，在此期间，它获得的锁过期了，而客户端2获得了锁。当客户端1从GC pause中恢复过来的时候，它不知道自己持有的锁已经过期了，它依然向共享资源（上图中是一个存储服务）发起了写数据请求，而这时锁实际上被客户端2持有，因此两个客户端的写请求就有可能冲突（锁的互斥作用失效了）。</p><p>如何解决这个问题呢?引入了fencing token的概念：</p><p><img src="/2019/08/13/redis实现分布式锁/Users/maxu/hexo/source/_posts/redis实现分布式锁/WX20190813-220732@2x.png" alt="img"></p><p>客户端1先获取到的锁，因此有一个较小的fencing token，等于33，而客户端2后获取到的锁，有一个较大的fencing token，等于34。客户端1从GC pause中恢复过来之后，依然是向存储服务发送访问请求，但是带了fencing token = 33。存储服务发现它之前已经处理过34的请求，所以会拒绝掉这次33的请求。这样就避免了冲突。</p><p>但是其实这已经超出了Redis实现分布式锁的范围，单纯用Redis没有命令来实现生成Token。</p><ul><li>时钟跳跃问题 假设有5个Redis节点A, B, C, D, E。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">客户端1从Redis节点A, B, C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。</span><br><span class="line">节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。</span><br><span class="line">客户端2从Redis节点C, D, E成功获取了同一个资源的锁（多数节点）。</span><br><span class="line">客户端1和客户端2现在都认为自己持有了锁。</span><br><span class="line">这个问题用Redis实现分布式锁暂时无解。而生产环境这种情况是存在的。</span><br></pre></td></tr></table></figure><p>结论 Redis并不能实现严格意义上的分布式锁。但是这并不意味着上面讨论的方案一无是处。如果你的应用场景为了效率(efficiency)，协调各个客户端避免做重复的工作，即使锁失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。但是如果你的应用场景是为了正确性(correctness)，那么用Redis实现分布式锁并不合适，会存在各种各样的问题，且解决起来就很复杂，为了正确性，需要使用zab、raft共识算法，或者使用带有事务的数据库来实现严格意义上的分布式锁。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-单机Redis实现分布式锁&quot;&gt;&lt;a href=&quot;#1-单机Redis实现分布式锁&quot; class=&quot;headerlink&quot; title=&quot;1.单机Redis实现分布式锁&quot;&gt;&lt;/a&gt;1.单机Redis实现分布式锁&lt;/h2&gt;&lt;h3 id=&quot;1-1获取锁&quot;&gt;&lt;a hr
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/tags/redis/"/>
    
  </entry>
  
  <entry>
    <title>分布式锁</title>
    <link href="http://yoursite.com/2019/08/13/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://yoursite.com/2019/08/13/分布式锁/</id>
    <published>2019-08-13T09:44:19.000Z</published>
    <updated>2019-08-13T12:38:13.514Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p>在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。</p><p>阻塞锁通常使用互斥量来实现：</p><ul><li>互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态；</li><li>互斥量为 1 表示未锁定状态。</li></ul><p>1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。</p><a id="more"></a><h2 id="数据库的唯一索引"><a href="#数据库的唯一索引" class="headerlink" title="数据库的唯一索引"></a>数据库的唯一索引</h2><p>获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否存于锁定状态。</p><p>存在以下几个问题：</p><ul><li>锁没有失效时间，解锁失败的话其它进程无法再获得该锁。</li><li>只能是非阻塞锁，插入失败直接就报错了，无法重试。</li><li>不可重入，已经获得锁的进程也必须重新获取锁。</li></ul><h2 id="Redis-的-SETNX-指令"><a href="#Redis-的-SETNX-指令" class="headerlink" title="Redis 的 SETNX 指令"></a>Redis 的 SETNX 指令</h2><p>使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。</p><p>SETNX 指令和数据库的唯一索引类似，保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。</p><p>EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。</p><h2 id="Redis-的-RedLock-算法"><a href="#Redis-的-RedLock-算法" class="headerlink" title="Redis 的 RedLock 算法"></a>Redis 的 RedLock 算法</h2><p>使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。</p><ul><li>尝试从 N 个互相独立 Redis 实例获取锁；</li><li>计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，那么就认为锁获取成功了；</li><li>如果锁获取失败，就到每个实例上释放锁。</li></ul><h2 id="Zookeeper-的有序节点"><a href="#Zookeeper-的有序节点" class="headerlink" title="Zookeeper 的有序节点"></a>Zookeeper 的有序节点</h2><h3 id="1-Zookeeper-抽象模型"><a href="#1-Zookeeper-抽象模型" class="headerlink" title="1. Zookeeper 抽象模型"></a>1. Zookeeper 抽象模型</h3><p>Zookeeper 提供了一种树形结构的命名空间，/app1/p_1 节点的父节点为 /app1。</p><p><img src="/2019/08/13/分布式锁/WX20190813-203526@2x.png" alt></p><h3 id="2-节点类型"><a href="#2-节点类型" class="headerlink" title="2. 节点类型"></a>2. 节点类型</h3><ul><li>永久节点：不会因为会话结束或者超时而消失；</li><li>临时节点：如果会话结束或者超时就会消失；</li><li>有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，以此类推。</li></ul><h3 id="3-监听器"><a href="#3-监听器" class="headerlink" title="3. 监听器"></a>3. 监听器</h3><p>为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。</p><h3 id="4-分布式锁实现"><a href="#4-分布式锁实现" class="headerlink" title="4. 分布式锁实现"></a>4. 分布式锁实现</h3><ul><li>创建一个锁目录 /lock；</li><li>当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点；</li><li>客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁；</li><li>执行业务代码，完成后，删除对应的子节点。</li></ul><h3 id="5-会话超时"><a href="#5-会话超时" class="headerlink" title="5. 会话超时"></a>5. 会话超时</h3><p>如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。可以看到，Zookeeper 分布式锁不会出现数据库的唯一索引实现的分布式锁释放锁失败问题。</p><h3 id="6-羊群效应"><a href="#6-羊群效应" class="headerlink" title="6. 羊群效应"></a>6. 羊群效应</h3><p>一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应），而我们只希望它的后一个子节点收到通知。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;p&gt;在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。&lt;/p&gt;
&lt;p&gt;阻塞锁通常使用互斥量来实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态；&lt;/li&gt;
&lt;li&gt;互斥量为 1 表示未锁定状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。&lt;/p&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>再探索引-索引优化</title>
    <link href="http://yoursite.com/2019/08/13/%E5%86%8D%E6%8E%A2%E7%B4%A2%E5%BC%95/"/>
    <id>http://yoursite.com/2019/08/13/再探索引/</id>
    <published>2019-08-12T16:41:13.000Z</published>
    <updated>2019-08-13T08:33:33.707Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-独立的列"><a href="#1-独立的列" class="headerlink" title="1. 独立的列"></a>1. 独立的列</h3><p>在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。</p><p>例如下面的查询不能使用 actor_id 列的索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> actor_id <span class="keyword">FROM</span> sakila.actor <span class="keyword">WHERE</span> actor_id + <span class="number">1</span> = <span class="number">5</span>;</span><br></pre></td></tr></table></figure><h3 id="2-多列索引"><a href="#2-多列索引" class="headerlink" title="2. 多列索引"></a>2. 多列索引</h3><p>在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT film_id, actor_ id FROM sakila.film_actor WHERE actor_id = 1 AND film_id = 1;</span><br></pre></td></tr></table></figure><h3 id="3-索引列的顺序"><a href="#3-索引列的顺序" class="headerlink" title="3. 索引列的顺序"></a>3. 索引列的顺序</h3><p>让选择性最强的索引列放在前面。</p><p>索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。</p><p>例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> staff_id)/<span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> staff_id_selectivity,</span><br><span class="line"><span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> customer_id)/<span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> customer_id_selectivity,</span><br><span class="line"><span class="keyword">COUNT</span>(*)</span><br><span class="line"><span class="keyword">FROM</span> payment;</span><br></pre></td></tr></table></figure><h3 id="4-前缀索引"><a href="#4-前缀索引" class="headerlink" title="4. 前缀索引"></a>4. 前缀索引</h3><p>对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。</p><p>前缀长度的选取需要根据索引选择性来确定。</p><h3 id="5-覆盖索引"><a href="#5-覆盖索引" class="headerlink" title="5. 覆盖索引"></a>5. 覆盖索引</h3><p>索引包含所有需要查询的字段的值。</p><p>具有以下优点：</p><ul><li>索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。</li><li>一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。</li><li>对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。</li></ul><h2 id="索引的优点"><a href="#索引的优点" class="headerlink" title="索引的优点"></a>索引的优点</h2><ul><li>大大减少了服务器需要扫描的数据行数。</li><li>帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。</li><li>将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。</li></ul><h2 id="索引的使用条件"><a href="#索引的使用条件" class="headerlink" title="索引的使用条件"></a>索引的使用条件</h2><ul><li>对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；</li><li>对于中到大型的表，索引就非常有效；</li><li>但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-独立的列&quot;&gt;&lt;a href=&quot;#1-独立的列&quot; class=&quot;headerlink&quot; title=&quot;1. 独立的列&quot;&gt;&lt;/a&gt;1. 独立的列&lt;/h3&gt;&lt;p&gt;在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。&lt;/p&gt;
&lt;p&gt;例如下面
      
    
    </summary>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>关于CMS的Young GC</title>
    <link href="http://yoursite.com/2019/08/12/%E5%85%B3%E4%BA%8ECMS%E7%9A%84Young-GC/"/>
    <id>http://yoursite.com/2019/08/12/关于CMS的Young-GC/</id>
    <published>2019-08-12T06:16:02.000Z</published>
    <updated>2019-08-12T07:32:00.559Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h2><p>​    CMS 收集器是一种最短回收时间为目标的收集器。在重视服务的相应速度，希望系统停顿时间最短，以给用户最好的体验</p><p>​    CMS 收集器，实现的算法是标记-清除算法，整个过程分为：</p><ul><li>初始标记</li><li>并发标记</li><li>重新标记</li><li>并发清除</li></ul><p>其中初始标记和重新标记需要 STW</p><a id="more"></a><h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><p>​    首先初始标记阶段找出 GC Root 所能直接关联的对象，速度很快，如 Java 栈中引用的对象、方法区中静态变量应用的对象和系统词典中应用的对象并标记，找出老年代对象在 eden 区有引用关系的对象并标记，最后把这些标记的对象复制到 to，在复制过程中还要判断活跃的对象 GC 年领是否已经达到了阈值，如果已经达到阈值，就直接晋升到老年代，YGC 结束之后将 from 和 to 的引用互换。其中大对象直接晋升到老年代，避免了在 eden 区、form、to 之间的复制。在发生 YGC 前，虚拟机会检查老年代最大的连续空间是否大于新生代所有对象的总空间，如果条件成立，那么进行 YGC 是安全的，如果不成立，检查虚拟机是允许担保失败，如果允许会检查老年代最大的连续空间是否大于历次晋升到老年代对象的平均大小或者新生代对象总大小，如果大于则进行 YGC ，如果条件不成立，或者虚拟机不允许空间担保失败，则进行一次 Full GC。</p><h2 id="CMS-收集器缺点"><a href="#CMS-收集器缺点" class="headerlink" title="CMS 收集器缺点"></a>CMS 收集器缺点</h2><ul><li>CMS 收集器对CPU 资源非常敏感</li><li>CMS 收收集器无法处理浮动垃圾，可能出现 “ Concureent Mode Failure” 失败而导致另一次 Full GC 的产生。要是 CMS 在运行期间预留的内存无法满足程序需要，就会出现一次 “ Concureent Mode Failure” ,这个时候虚拟机临时启动 Serial Old 收集器重新来进行老年代的垃圾收集，这样停顿时间就很长了。</li><li>大量空间碎片，空间碎片过多的话会给分配大对象带来麻烦，即使老年代有很大的空间但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次 Full GC, 为了解决这个问题，CMS 提供了内存碎片整理的参数来设置，或者我进行几次不带碎片整理的 Full GC 之后，随后带一次碎片整理的 Full GC。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;CMS-收集器&quot;&gt;&lt;a href=&quot;#CMS-收集器&quot; class=&quot;headerlink&quot; title=&quot;CMS 收集器&quot;&gt;&lt;/a&gt;CMS 收集器&lt;/h2&gt;&lt;p&gt;​    CMS 收集器是一种最短回收时间为目标的收集器。在重视服务的相应速度，希望系统停顿时间最短，以给用户最好的体验&lt;/p&gt;
&lt;p&gt;​    CMS 收集器，实现的算法是标记-清除算法，整个过程分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始标记&lt;/li&gt;
&lt;li&gt;并发标记&lt;/li&gt;
&lt;li&gt;重新标记&lt;/li&gt;
&lt;li&gt;并发清除&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中初始标记和重新标记需要 STW&lt;/p&gt;
    
    </summary>
    
    
      <category term="JVM" scheme="http://yoursite.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>threadlocal内存泄漏</title>
    <link href="http://yoursite.com/2019/07/12/threadlocal%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F/"/>
    <id>http://yoursite.com/2019/07/12/threadlocal内存泄漏/</id>
    <published>2019-07-12T07:30:29.000Z</published>
    <updated>2019-08-12T08:10:59.024Z</updated>
    
    <content type="html"><![CDATA[<h2 id="ThreadLocal-原理"><a href="#ThreadLocal-原理" class="headerlink" title="ThreadLocal 原理"></a>ThreadLocal 原理</h2><p>由于ThreadLocalMap的key是弱引用，而Value是强引用。这就导致了一个问题，ThreadLocal在没有外部对象强引用时，发生GC时弱引用Key会被回收，而Value不会回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。</p><p><img src="/2019/07/12/threadlocal内存泄漏/F352F038-78E0-4AD0-A817-DC807B20E808.png" alt="F352F038-78E0-4AD0-A817-DC807B20E808"></p><a id="more"></a><p><strong>ThreadLocal 原理</strong>：每个 Thread 内维护着一个 ThreadLocalMap，它是一个 Map,这个映射表中 Key 为一个弱引用，就是 ThreadLocal 本身，value 就是我们存储的对象。</p><p>也就是说 ThreadLocal 是一个工具，来维护 ThreadLocalMap 来存取数值，注意图上的虚线，它代表一个弱引用，而弱引用的生命周期只能存活在下一次 GC.</p><h1 id="ThreadLocal-为什么出现内存泄漏"><a href="#ThreadLocal-为什么出现内存泄漏" class="headerlink" title="ThreadLocal 为什么出现内存泄漏"></a>ThreadLocal 为什么出现内存泄漏</h1><p>ThreadLocal 在 ThreadLocalMap中是以一个弱引用身份被Entry中的Key引用的，因此如果 ThreadLocal 没有外部强引用来引用它，那么ThreadLocal会在下次JVM垃圾收集时被回收。这个时候就会出现Entry中Key已经被回收，出现一个null Key的情况，外部读取 ThreadLocalMap 中的元素是无法通过 null Key 来找到 Value 的。因此如果当前线程的生命周期很长，一直存在，那么其内部的ThreadLocalMap对象也一直生存下来，这些null key就存在一条强引用链的关系一直存在：Thread –&gt; ThreadLocalMap–&gt;Entry–&gt;Value，这条强引用链会导致Entry不会回收，Value也不会回收，但Entry中的Key却已经被回收的情况，造成内存泄漏。</p><p>但是JVM团队已经考虑到这样的情况，并做了一些措施来保证 ThreadLocal 尽量不会内存泄漏：在 ThreadLocal 的get()、set()、remove()方法调用的时候会清除掉线程 ThreadLocalMap 中所有 Entry 中 Key 为 null 的 Value，并将整个 Entry 设置为 null，利于下次内存回收。</p><p>来看看ThreadLocal的get()方法底层实现</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> T <span class="title">get</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    Thread t = Thread.currentThread();</span><br><span class="line">    ThreadLocalMap map = getMap(t);</span><br><span class="line">    <span class="keyword">if</span> (map != <span class="keyword">null</span>) &#123;</span><br><span class="line">        ThreadLocalMap.Entry e = map.getEntry(<span class="keyword">this</span>);</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>)</span><br><span class="line">            <span class="keyword">return</span> (T)e.value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> setInitialValue();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在调用map.getEntry(this)时，内部会判断key是否为null，继续看map.getEntry(this)源码</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Entry <span class="title">getEntry</span><span class="params">(ThreadLocal key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = key.threadLocalHashCode &amp; (table.length - <span class="number">1</span>);</span><br><span class="line">    Entry e = table[i];</span><br><span class="line">    <span class="keyword">if</span> (e != <span class="keyword">null</span> &amp;&amp; e.get() == key)</span><br><span class="line">        <span class="keyword">return</span> e;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> getEntryAfterMiss(key, i, e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在getEntry方法中，如果Entry中的key发现是null，会继续调用getEntryAfterMiss(key, i, e)方法，其内部回做回收必要的设置，继续看内部源码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Entry <span class="title">getEntryAfterMiss</span><span class="params">(ThreadLocal key, <span class="keyword">int</span> i, Entry e)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">while</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">        ThreadLocal k = e.get();</span><br><span class="line">        <span class="keyword">if</span> (k == key)</span><br><span class="line">            <span class="keyword">return</span> e;</span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>)</span><br><span class="line">            expungeStaleEntry(i);</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            i = nextIndex(i, len);</span><br><span class="line">        e = tab[i];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意k == null这里，继续调用了expungeStaleEntry(i)方法，expunge的意思是擦除，删除的意思，见名知意，在来看expungeStaleEntry方法的内部实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">expungeStaleEntry</span><span class="params">(<span class="keyword">int</span> staleSlot)</span> </span>&#123;</span><br><span class="line">    Entry[] tab = table;</span><br><span class="line">    <span class="keyword">int</span> len = tab.length;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// expunge entry at staleSlot（意思是，删除value，设置为null便于下次回收）</span></span><br><span class="line">    tab[staleSlot].value = <span class="keyword">null</span>;</span><br><span class="line">    tab[staleSlot] = <span class="keyword">null</span>;</span><br><span class="line">    size--;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// Rehash until we encounter null</span></span><br><span class="line">    Entry e;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i = nextIndex(staleSlot, len);</span><br><span class="line">         (e = tab[i]) != <span class="keyword">null</span>;</span><br><span class="line">         i = nextIndex(i, len)) &#123;</span><br><span class="line">        ThreadLocal k = e.get();</span><br><span class="line">        <span class="keyword">if</span> (k == <span class="keyword">null</span>) &#123;</span><br><span class="line">            e.value = <span class="keyword">null</span>;</span><br><span class="line">            tab[i] = <span class="keyword">null</span>;</span><br><span class="line">            size--;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> h = k.threadLocalHashCode &amp; (len - <span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span> (h != i) &#123;</span><br><span class="line">                tab[i] = <span class="keyword">null</span>;</span><br><span class="line"> </span><br><span class="line">                <span class="comment">// Unlike Knuth 6.4 Algorithm R, we must scan until</span></span><br><span class="line">                <span class="comment">// null because multiple entries could have been stale.</span></span><br><span class="line">                <span class="keyword">while</span> (tab[h] != <span class="keyword">null</span>)</span><br><span class="line">                    h = nextIndex(h, len);</span><br><span class="line">                tab[h] = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意这里，将当前Entry删除后，会继续循环往下检查是否有key为null的节点，如果有则一并删除，防止内存泄漏。但这样也并不能保证 ThreadLoca l不会发生内存泄漏，例如：</p><ul><li>使用 static 的 ThreadLocal，延长了ThreadLocal的生命周期，可能导致的内存泄漏。</li><li>分配使用了 ThreadLocal 又不再调用get()、set()、remove()方法，那么就会导致内存泄漏。</li></ul><h3 id="为什么使用弱引用？"><a href="#为什么使用弱引用？" class="headerlink" title="为什么使用弱引用？"></a>为什么使用弱引用？</h3><p>从表面上看，发生内存泄漏，是因为Key使用了弱引用类型。但其实是因为整个Entry的key为null后，没有主动清除value导致。很多文章大多分析ThreadLocal使用了弱引用会导致内存泄漏，但为什么使用弱引用而不是强引用？</p><p>官方文档的说法：</p><blockquote><p>To help deal with very large and long-lived usages, the hash table entries use WeakReferences for keys.<br>为了处理非常大和生命周期非常长的线程，哈希表使用弱引用作为 key。</p></blockquote><p>下面我们分两种情况讨论：</p><ul><li>key 使用强引用：引用的ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal不会被回收，导致Entry内存泄漏。</li><li>key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal也会被回收。value在下一次ThreadLocalMap调用set,get，remove的时候会被清除。<br>比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障：弱引用ThreadLocal不会内存泄漏，对应的value在下一次ThreadLocalMap调用set,get,remove的时候会被清除。</li></ul><p>因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key的value就会导致内存泄漏，而不是因为弱引用。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>综合上面的分析，我们可以理解ThreadLocal内存泄漏的前因后果，那么怎么避免内存泄漏呢？</p><ul><li>每次使用完ThreadLocal，都调用它的remove()方法，清除数据。</li></ul><p>在使用线程池的情况下，没有及时清理ThreadLocal，不仅是内存泄漏的问题，更严重的是可能导致业务逻辑出现问题。所以，使用ThreadLocal就跟加锁完要解锁一样，用完就清理。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;ThreadLocal-原理&quot;&gt;&lt;a href=&quot;#ThreadLocal-原理&quot; class=&quot;headerlink&quot; title=&quot;ThreadLocal 原理&quot;&gt;&lt;/a&gt;ThreadLocal 原理&lt;/h2&gt;&lt;p&gt;由于ThreadLocalMap的key是弱引用，而Value是强引用。这就导致了一个问题，ThreadLocal在没有外部对象强引用时，发生GC时弱引用Key会被回收，而Value不会回收，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2019/07/12/threadlocal内存泄漏/F352F038-78E0-4AD0-A817-DC807B20E808.png&quot; alt=&quot;F352F038-78E0-4AD0-A817-DC807B20E808&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>mysql主从复制和读写分离过程</title>
    <link href="http://yoursite.com/2019/06/23/mysql%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E5%92%8C%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E8%BF%87%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/06/23/mysql主从复制和读写分离过程/</id>
    <published>2019-06-23T07:08:25.000Z</published>
    <updated>2019-08-13T07:24:57.866Z</updated>
    
    <content type="html"><![CDATA[<h2 id="主从复制"><a href="#主从复制" class="headerlink" title="主从复制"></a>主从复制</h2><p>主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。</p><ul><li><p><strong>binlog 线程</strong> ：负责将主服务器上的数据更改写入二进制日志（Binary log）中。</p></li><li><p><strong>I/O 线程</strong> ：负责从主服务器上读取二进制日志，并写入从服务器的中继日志（Relay log）。</p></li><li><p><strong>SQL 线程</strong> ：负责读取中继日志，解析出主服务器已经执行的数据更改并在从服务器中重放（Replay）。</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/WX20190813-151216@2x.png" alt></p></li></ul><h2 id="读写分离"><a href="#读写分离" class="headerlink" title="读写分离"></a>读写分离</h2><p>主服务器处理写操作以及实时性要求比较高的读操作，而从服务器处理读操作。</p><p>读写分离能提高性能的原因在于：</p><ul><li>主从服务器负责各自的读和写，极大程度缓解了锁的争用；</li><li>从服务器可以使用 MyISAM，提升查询性能以及节约系统开销；</li><li>增加冗余，提高可用性。</li></ul><p>读写分离常用代理方式来实现，代理服务器接收应用层传来的读写请求，然后决定转发到哪个服务器。</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/WX20190813-152300@2x.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;主从复制&quot;&gt;&lt;a href=&quot;#主从复制&quot; class=&quot;headerlink&quot; title=&quot;主从复制&quot;&gt;&lt;/a&gt;主从复制&lt;/h2&gt;&lt;p&gt;主要涉及三个线程：binlog 线程、I/O 线程和 SQL 线程。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;bin
      
    
    </summary>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>mysql索引</title>
    <link href="http://yoursite.com/2019/06/10/mysql%E7%B4%A2%E5%BC%95/"/>
    <id>http://yoursite.com/2019/06/10/mysql索引/</id>
    <published>2019-06-10T08:38:15.000Z</published>
    <updated>2019-08-12T09:00:12.452Z</updated>
    
    <content type="html"><![CDATA[<p>想必大家一提到索引都不陌生，在工作中经常接触到。比如我们一个 SQL 查询比较慢的时候，我们会给某个字段添加索引这样的方法来解决。</p><p>一句话简单的说，索引的出现就是为了提高查询的效率，就像书的目录一样。一本书有 1000 页，如果我们想要快速找到其中某一个知识点，如果不借助目录，我们查询可能会花费比较长的时间，如果我们借助目录的话，可以对我们查找的效率有了很明显的提升。其实对于数据库表而言，索引就是它的“目录”。</p><a id="more"></a><h2 id="索引的常见模型"><a href="#索引的常见模型" class="headerlink" title="索引的常见模型"></a>索引的常见模型</h2><p>索引的出现是为了提高查询效率，实现索引的方式有很多，比较常见的有哈希表、有序数组、和搜索树。</p><h3 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h3><p> 哈希表是一种 key-value 存储的数据结构，我们只要输入带查找的的数值 key,就可以找到相对应的数值 value。哈希表的思路非常简单，我们把数值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。不可避免地是多个 key 数值经过哈希函数的换算，会出现同一个数值的情况。处理这种昂情况的一种方法是，拉出一个链表。（这里就跟 JDK 中的 HashMap 中的处理类似 ）</p><p><img src="/2019/06/10/mysql索引/FE4B01D7-65BB-48F2-8E75-D84DDDB97273.png" alt="FE4B01D7-65BB-48F2-8E75-D84DDDB97273"></p><p>图中，User2 和 User4 根据身份证号算出来的值都是 N，但没关系，后面还跟了一个链表。假设，这时候你要查 ID_card_n2 对应的名字是什么，处理步骤就是：首先，将 ID_card_n2 通过哈希函数算出 N；然后，按顺序遍历，找到 User2。需要注意的是，图中四个 ID_card_n 的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。</p><p>你可以设想下，如果你现在要找身份证号在[ID_card_X, ID_card_Y] 这个区间的所有用户，就必须全部扫描一遍了。所以，<strong>哈希表这种结构适用于只有等值查询的场景，</strong>比如 Memcached 及其他一些 NoSQL 引擎。<strong>而有序数组在等值查询和范围查询场景中的性能就都非常优秀</strong>。还是上面这个根据身份证号查名字的例。那么我如果使用有序数组的话。</p><h3 id="有序数组"><a href="#有序数组" class="headerlink" title="有序数组"></a>有序数组</h3><p><img src="/2019/06/10/mysql索引/WX20190812-165307@2x.png" alt></p><p>这里我们假设身份证号没有重复，这个数组就是按照身份证号递增的顺序保存的。这时候如果你要查ID_card_n2对应的名字，用二分法就可以快速得到，这个时间复杂度是 O(log(N))。同时很显然，这个索引结构支持范围查询。你要查身份证号在[ID_card_X, ID_card_Y]区间的 User，可以先用二分法找到 ID_card_X（如果不存在ID_card_X，就找到大于 ID_card_X 的第一个User），然后向右遍历，直到查到第一个大于 ID_card_Y 的身份证号，退出循环。如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。</p><p>所以，<strong>有序数组索引只适用于静态存储引擎</strong>，比如你要保存的是2018年某个城市的所有人口信息，这类不会再修改的数据。</p><h3 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h3><p><img src="/2019/06/10/mysql索引/WX20190812-165402@2x.png" alt></p><p>二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -&gt; UserC -&gt; UserF -&gt; User2 这个路径得到。这个时间复杂度是 O(log(N))。</p><p>当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。</p><p>我们可以想象一下一棵 100 万节点的平衡二叉树，树高 20。一次查询可能需要访问 20 个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要 10 ms 左右的寻址时间。也就是说，对于一个 100 万行的表，如果使用二叉树来存储，单独访问一个行可能需要 20 个 10 ms 的时间，这个查询可真够慢的。为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。</p><h2 id="InnoDB-的索引模型"><a href="#InnoDB-的索引模型" class="headerlink" title="InnoDB 的索引模型"></a>InnoDB 的索引模型</h2><p>nnoDB使用了B+树索引模型，所以数据都是存储在B+树中的。</p><p><strong>每一个索引在InnoDB里面对应一棵B+树。</strong></p><p>假设，我们有一个主键列为ID的表，表中有字段k，并且在k上有索引。</p><p>这个表的建表语句是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">mysql&gt; create table T(</span><br><span class="line">id int primary key,</span><br><span class="line">k int not null,</span><br><span class="line">name varchar(16),</span><br><span class="line">index (k))engine=InnoDB</span><br></pre></td></tr></table></figure><p>表中R1~R5的(ID,k)值分别为(100,1)、(200,2)、(300,3)、(500,5)和(600,6)，两棵树的示例示意图如下.</p><p><img src="/2019/06/10/mysql索引/WX20190812-165415@2x.png" alt></p><p>从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。</p><p><strong>主键索引的叶子节点存的是整行数据</strong>。在InnoDB里，<strong>主键索引也被称为聚簇索引</strong>（clustered index）。</p><p><strong>非主键索引的叶子节点内容是主键的值</strong>。在InnoDB里，非主键索引也被称为二级索引（secondary index）。</p><p>根据上面的索引结构说明，我们来讨论一个问题：<strong>基于主键索引和普通索引的查询有什么区别？</strong></p><ul><li>如果语句是select * from T where ID=500，即主键查询方式，则只需要搜索ID这棵B+树；</li><li>如果语句是select * from T where k=5，即普通索引查询方式，则需要先搜索k索引树，得到ID的值为500，再到ID索引树搜索一次。这个过程称为回表。</li></ul><p>也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。</p><h2 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h2><p>索引只能定位到 page, page 内部有个有序数组，通过二分法进行查找具体的数据。</p><p>B+树为了维护索引有序性，在插入新值的时候需要做必要的维护。以上面这个图为例，如果插入新的行 ID 值为 700，则只需要在 R5 的记录后面插入一个新记录。如果新插入的 ID 值为 400，就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。</p><p>除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。基于上面的索引维护过程说明，我们来讨论一个案例：</p><blockquote><p>你可能在一些建表规范里面见到过类似的描述，要求建表语句里一定要有自增主键。当然事无绝对，我们来分析一下哪些场景下应该使用自增主键，而哪些场景下不应该。</p></blockquote><p>自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的： NOT NULL PRIMARY KEY AUTO_INCREMENT。插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。</p><p>也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？</p><p>由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。</p><p>显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。所以，从性能和存储空间方面考量，自增主键往往是更合理的选择。有没有什么场景适合用业务字段直接做主键的呢？还是有的。比如，有些业务的场景需求是这样的：</p><ol><li>只有一个索引；</li><li>该索引必须是唯一索引。</li></ol><p>这就是典型的KV场景。</p><p>由于没有其他索引，所以也就不用考虑其他索引的叶子节点大小的问题。</p><p>这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则，直接将这个索引设置为主键，可以避免每次查询需要搜索两棵树。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;想必大家一提到索引都不陌生，在工作中经常接触到。比如我们一个 SQL 查询比较慢的时候，我们会给某个字段添加索引这样的方法来解决。&lt;/p&gt;
&lt;p&gt;一句话简单的说，索引的出现就是为了提高查询的效率，就像书的目录一样。一本书有 1000 页，如果我们想要快速找到其中某一个知识点，如果不借助目录，我们查询可能会花费比较长的时间，如果我们借助目录的话，可以对我们查找的效率有了很明显的提升。其实对于数据库表而言，索引就是它的“目录”。&lt;/p&gt;
    
    </summary>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>count(1) 和 count(*)的区别</title>
    <link href="http://yoursite.com/2019/05/13/count-1-%E5%92%8Ccount-%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2019/05/13/count-1-和count-的区别/</id>
    <published>2019-05-13T09:32:19.000Z</published>
    <updated>2019-08-11T14:54:15.259Z</updated>
    
    <content type="html"><![CDATA[<p>Count 是一种简单的聚合函数，一般也是我们第一个开始学习的聚合函数，那么他们之间究竟有什么区别呢？</p><p>有人说 count(1) 和 count(*) 他们之间有区别，而有的人说他们之间没有区别那么他们之间到底有没有区别呢？</p><a id="more"></a><h2 id="执行结果"><a href="#执行结果" class="headerlink" title="执行结果"></a>执行结果</h2><p>count(1) 和 count(*) 之间没有区别，因为 count(*) 、count(1) 都不会去空值。单count(列名) 就有区别了，因为 count(列名) 回去过滤控制。</p><h2 id="执行效率"><a href="#执行效率" class="headerlink" title="执行效率"></a>执行效率</h2><p>他们之间根据不同情况会有些许区别，MySQL会对count（*）做优化。</p><ol><li>如果列为主键，count(列名)效率优于count(1) </li><li>如果列不为主键，count(1)效率优于count(列名)  </li><li>如果表中存在主键，count(主键列名)效率最优  </li><li>如果表中只有一列，则count(*)效率最优  </li><li>如果表有多列，且不存在主键，则count(1)效率优于count(*)</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Count 是一种简单的聚合函数，一般也是我们第一个开始学习的聚合函数，那么他们之间究竟有什么区别呢？&lt;/p&gt;
&lt;p&gt;有人说 count(1) 和 count(*) 他们之间有区别，而有的人说他们之间没有区别那么他们之间到底有没有区别呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>数据库优化</title>
    <link href="http://yoursite.com/2019/05/13/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96/"/>
    <id>http://yoursite.com/2019/05/13/数据库优化/</id>
    <published>2019-05-13T09:15:32.000Z</published>
    <updated>2019-08-11T15:11:52.705Z</updated>
    
    <content type="html"><![CDATA[<p>数据库是我们开发中会经常使用到，那我们今天来聊一下在数据库方面所发生的问题，今天我主要学习了一下这个三个方面的知识，来给大家分享一下。</p><ol><li>库表设计 ？</li><li>慢 SQL 问题 ？</li><li>误操作、程序 bug 时怎么办 ？</li></ol><a id="more"></a><h2 id="一、库表设计"><a href="#一、库表设计" class="headerlink" title="一、库表设计"></a>一、库表设计</h2><h3 id="1-1-引擎的选择"><a href="#1-1-引擎的选择" class="headerlink" title="1.1 引擎的选择"></a>1.1 引擎的选择</h3><p>在 mysql 5.1 中，引入了新的插件式存储引擎体系结构，允许将存储引擎加载到正在运新的 mysql 服务器中。使用 mysql 插件式存储引擎体系结构，允许数据库专业人员或者设计库表的软件开发人员为特定的应用需求选择专门的存储引擎，完全不需要管理任何特殊的应用编码要求，也无需考虑所有的底层实施细节。因此，尽管不同的存储引擎具有不同的能力，应用程序是与之分离的。此外，使用者可以在服务器、数据库和表格三个层级中存储引擎，提供了极大的灵活性。</p><p>mysql 常用的存储引擎包括 MYISAM、Innodb 和 Memory，其中各自的特点如下：</p><ol><li>MYISAM : 全表锁，拥有较高的执行速度，一个写请求请阻塞另外相同表格的所有读写请求，并发性能差，占用空间相对较小，mysql 5.5 及以下仅 MYISAM 支持全文索引，不支持事务。</li><li>Innodb：行级锁（SQL 都走索引查询），并发能力相对强，占用空间是 MYISAM 的 2.5 倍，不支持全文索引（5.6 开始支持），支持事务。</li><li>Memory : 全表锁，存储在内存当中，速度快，但会占用和数据量成正比的内存空间且数据在 mysql 重启时会丢失。</li></ol><blockquote><p>基于以上特性，建议绝大部份都设置为 innodb 引擎，特殊的业务再考虑选用 MYISAM 或 Memory ，如全文索引支持或极高的执行效率等。</p></blockquote><h3 id="1-2-分表的方法"><a href="#1-2-分表的方法" class="headerlink" title="1.2 分表的方法"></a>1.2 分表的方法</h3><p>数据库表使用过程中，为了减小数据库服务器的负担、缩短查询时间，常常会考虑做分表设计。分表分两种，一种是纵向分表（将本来可以在同一个表的内容，人为划分存储在为多个不同结构的表）和横向分表（把大的表结构，横向切割为同样结构的不同表）。</p><p>其中，纵向分表常见的方式有根据活跃度分表、根据重要性分表等。其主要解决问题如下：</p><ol><li>表与表之间资源争用问题；</li><li>锁争用机率小；</li><li>实现核心与非核心的分级存储，如UDB登陆库拆分成一级二级三级库；</li><li>解决了数据库同步压力问题。</li></ol><p>横向分表是指根据某些特定的规则来划分大数据量表，如根据时间分表。其主要解决问题如下：</p><ol><li>单表过大造成的性能问题；</li><li>单表过大造成的单服务器空间问题。</li></ol><h3 id="1-3-索引问题"><a href="#1-3-索引问题" class="headerlink" title="1.3 索引问题"></a><strong>1.3 索引问题</strong></h3><p>索引是对数据库表中一个或多个列的值进行排序的结构，建立索引有助于更快地获取信息。 mysql 有四种不同的索引类型：</p><ol><li><ol><li>主键索此 ( PRIMARY )</li><li>唯一索引 ( UNIQUE )</li><li>普通索引 ( INDEX )</li><li>全文索引（FULLTEXT , MYISAM 及 mysql 5.6 以上的 Innodb ）</li></ol></li></ol><p>建立索引的目的是加快对表中记录的查找或排序，索引也并非越多越好，因为创建索引是要付出代价的：一是增加了数据库的存储空间，二是在插入和修改数据时要花费较多的时间维护索引。</p><p>在设计表或索引时，常出现以下几个问题：</p><ol><li>少建索引或不建索引。这个问题最突出，建议建表时 DBA 可以一起协助把关</li><li>索引滥用。滥用索引将导致写请求变慢，拖慢整体数据库的响应速度（5.5 以下的 mysql 只能用到一个索引)。</li><li>从不考虑联合索引。实际上联合索引的效率往往要比单列索引的效率更高。</li><li>非最优列选择。低选择性的字段不适合建单列索引，如 status 类型的字段。</li></ol><h2 id="二、慢-SQL-问题"><a href="#二、慢-SQL-问题" class="headerlink" title="二、慢 SQL 问题"></a>二、慢 SQL 问题</h2><h3 id="2-1-导致慢-SQL-的原因"><a href="#2-1-导致慢-SQL-的原因" class="headerlink" title="2.1 导致慢 SQL 的原因"></a><strong>2.1 导致慢 SQL 的原因</strong></h3><p>在遇到慢 SQL 情况时，不能简单的把原因归结为 SQL 编写问题(虽然这是最常见的因素)，实际上导致慢 SQL 有很多因素，甚至包括硬件和 mysql 本身的 bug。根据出现的概率从大到小，罗列如下：</p><ol><li>SQL编写问题</li><li>锁</li><li>业务实例相互干绕对 IO/CPU 资源争用</li><li>服务器硬件</li><li>MYSQL BUG</li></ol><h3 id="2-2-由-SQL-编写导致的慢-SQL-优化"><a href="#2-2-由-SQL-编写导致的慢-SQL-优化" class="headerlink" title="2.2 由 SQL 编写导致的慢 SQL 优化"></a><strong>2.2 由 SQL 编写导致的慢 SQL 优化</strong></h3><p>针对SQL编写导致的慢 SQL，优化起来还是相对比较方便的。正如上一节提到的正确的使用索引能加快查询速度，那么我们在编写 SQL 时就需要注意与索引相关的规则：</p><ol><li>字段类型转换导致不用索引，如字符串类型的不用引号，数字类型的用引号等，这有可能会用不到索引导致全表扫描；</li><li>mysql 不支持函数转换，所以字段前面不能加函数，否则这将用不到索引；</li><li>不要在字段前面加减运算；</li><li>字符串比较长的可以考虑索引一部份减少索引文件大小，提高写入效率；</li><li>like % 在前面用不到索引；</li><li>根据联合索引的第二个及以后的字段单独查询用不到索引；</li><li>不要使用 select *；</li><li>排序请尽量使用升序 ;</li><li>or 的查询尽量用 union 代替 （Innodb）；</li><li>复合索引高选择性的字段排在前面；</li><li>order by / group by 字段包括在索引当中减少排序，效率会更高。</li></ol><p>除了上述索引使用规则外，SQL 编写时还需要特别注意一下几点：</p><ol><li>尽量规避大事务的 SQL，大事务的 SQL 会影响数据库的并发性能及主从同步；</li><li>分页语句 limit 的问题；</li><li>删除表所有记录请用 truncate，不要用 delete；</li><li>不让 mysql 干多余的事情，如计算；</li><li>输写 SQL 带字段，以防止后面表变更带来的问题，性能也是比较优的 ( 涉及到数据字典解析，请自行查询资料)；</li><li>在 Innodb上用 select count(*)，因为 Innodb 会存储统计信息；</li><li>慎用 Oder by rand()。</li></ol><h2 id="三、分析诊断工具"><a href="#三、分析诊断工具" class="headerlink" title="三、分析诊断工具"></a><strong>三、分析诊断工具</strong></h2><p>在日常开发工作中，我们可以做一些工作达到预防慢 SQL 问题，比如在上线前预先用诊断工具对 SQL 进行分析。常用的工具有：</p><ol><li>mysqldumpslow</li><li>mysql profile</li><li>mysql explain</li></ol><p>具体使用及分析方法在此就不赘述，网上有丰富的资源可以参考。</p><h2 id="四、误操作、程序-bug-时怎么办"><a href="#四、误操作、程序-bug-时怎么办" class="headerlink" title="四、误操作、程序 bug 时怎么办"></a><strong>四、误操作、程序 bug 时怎么办</strong></h2><p>当你发现误操作或程序 bug 导致线上数据被误删或误改动时，一定不能慌乱，应及时与 DBA 联系，第一时间进行数据恢复（严重时直接停止服务），尽可能减少影响和损失。对于重要数据（如资金）的操作，在开发时一定要反复进行测试，确保没有问题后再上线。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;数据库是我们开发中会经常使用到，那我们今天来聊一下在数据库方面所发生的问题，今天我主要学习了一下这个三个方面的知识，来给大家分享一下。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;库表设计 ？&lt;/li&gt;
&lt;li&gt;慢 SQL 问题 ？&lt;/li&gt;
&lt;li&gt;误操作、程序 bug 时怎么办 ？&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="数据库" scheme="http://yoursite.com/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>JVM优化</title>
    <link href="http://yoursite.com/2019/05/12/JVM%E4%BC%98%E5%8C%96/"/>
    <id>http://yoursite.com/2019/05/12/JVM优化/</id>
    <published>2019-05-12T03:42:43.000Z</published>
    <updated>2019-08-11T05:25:14.655Z</updated>
    
    <content type="html"><![CDATA[<h2 id="JVM运行参数"><a href="#JVM运行参数" class="headerlink" title="JVM运行参数"></a>JVM运行参数</h2><h3 id="三种参数类型"><a href="#三种参数类型" class="headerlink" title="三种参数类型"></a>三种参数类型</h3><ul><li><p>标准参数</p><ul><li>-help</li><li>-version</li><li>-D 设置程序运行的参数</li><li>-server  使用并行的垃圾收集器，启动慢，运行快</li><li>-client 使用串行的垃圾收集器，启动快，运行慢</li></ul></li><li><p>-X参数（非标准参数）</p><ul><li>-Xint </li><li>-Xcomp</li><li>-Xmixed</li><li>-Xms 堆的初始大小</li><li>-Xmx 堆的最大大小</li></ul></li><li><p>-XX 参数（使用率较高）</p><ul><li>-XX: newSize</li><li>-XX:+UseSerialGC</li><li>-XX:newRadio</li><li>-XX:+PrintFlagsFinal 输出JVM运行时的参数</li></ul></li></ul><p><img src="/2019/05/12/JVM优化/E:/Git\TTMS\MX-Notes\image\1557634794531.png" alt="1557634794531"></p><p>jps</p><p>jinfo -flags 进程id</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;JVM运行参数&quot;&gt;&lt;a href=&quot;#JVM运行参数&quot; class=&quot;headerlink&quot; title=&quot;JVM运行参数&quot;&gt;&lt;/a&gt;JVM运行参数&lt;/h2&gt;&lt;h3 id=&quot;三种参数类型&quot;&gt;&lt;a href=&quot;#三种参数类型&quot; class=&quot;headerlink&quot; 
      
    
    </summary>
    
    
      <category term="JVM" scheme="http://yoursite.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>一次完整的http请求过程</title>
    <link href="http://yoursite.com/2019/05/11/%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E7%9A%84http%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/05/11/一次完整的http请求过程/</id>
    <published>2019-05-11T13:55:48.000Z</published>
    <updated>2019-08-11T05:25:14.657Z</updated>
    
    <content type="html"><![CDATA[<p>当我们在浏览器上输入 <a href="http://www.xxx.com" target="_blank" rel="noopener">www.xxx.com</a> 然后回车，回车这一瞬间到底发生了什么？</p><p>首先是域名解析，然后是建立 TCP 三次握手，建立 TCP 连接之后发起 HTTP 请求，服务器响应请求，浏览器获得 HTML 代码，浏览器解析 HTML 代码，并请求 HTML 代码中的资源，浏览器开始对页面进行渲染将页面呈现给用户。</p><h2 id="域名解析"><a href="#域名解析" class="headerlink" title="域名解析"></a>域名解析</h2><ul><li>首先浏览器会搜索自身的 DNS 缓存，如果有该条目，如果没有过期则返回。</li><li>如果浏览器缓存中没有找到，此时会查找操作系统本地 DNS 缓存，查看方式 ipconfig/displaydns。</li><li>如果操作系统的 DNS 缓存没有查找到则开始读取 host 文件的缓存，如果有则解析成功。</li><li>如果 host 文件中没有找到则计算机发起一个 DNS 的系统调用，向本地配置的 DNS 服务器发送一个域名解析的请求，运营商的 DNS 服务器首先会查找本地缓存，如果有则解析成功，如果没有则 DNS 服务器会代替我们浏览器发起迭代的请求，首先想根域名，然后从右向左，逐一进行请求。</li></ul><p>浏览器拿到 index.html 文件后，就开始解析其中的 html 代码，遇到 js/css/image 等静态资源时，就向服务器端去请求下载（会使用多线程下载，每个浏览器的线程数不一样），这个时候就用上 keep-alive 特性了，建立一次HTTP连接，可以请求多个资源，下载资源的顺序就是按照代码里的顺序，但是由于每个资源大小不一样，而浏览器又多线程请求请求资源，所以从下图看出，这里显示的顺序并不一定是代码里面的顺序。</p><p>浏览器在请求静态资源时（在未过期的情况下），向服务器端发起一个 http 请求（询问自从上一次修改时间到现在有没有对资源进行修改），如果服务器端返回304状态码（告诉浏览器服务器端没有修改），那么浏览器会直接读取本地的该资源的缓存文件。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;当我们在浏览器上输入 &lt;a href=&quot;http://www.xxx.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;www.xxx.com&lt;/a&gt; 然后回车，回车这一瞬间到底发生了什么？&lt;/p&gt;
&lt;p&gt;首先是域名解析，然后是建立 TCP 三次握手，
      
    
    </summary>
    
    
      <category term="网络" scheme="http://yoursite.com/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>事务的隔离级别和传播机制</title>
    <link href="http://yoursite.com/2019/05/11/%E4%BA%8B%E5%8A%A1%E7%9A%84%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%E5%92%8C%E4%BC%A0%E6%92%AD%E6%9C%BA%E5%88%B6/"/>
    <id>http://yoursite.com/2019/05/11/事务的隔离级别和传播机制/</id>
    <published>2019-05-11T13:54:43.000Z</published>
    <updated>2019-08-11T05:25:14.657Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>redis</title>
    <link href="http://yoursite.com/2019/05/10/redis/"/>
    <id>http://yoursite.com/2019/05/10/redis/</id>
    <published>2019-05-10T00:14:55.000Z</published>
    <updated>2019-08-11T05:25:14.656Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>进程和线程</title>
    <link href="http://yoursite.com/2019/05/10/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/05/10/进程和线程/</id>
    <published>2019-05-09T16:23:53.000Z</published>
    <updated>2019-08-11T05:25:14.658Z</updated>
    
    <content type="html"><![CDATA[<h2 id="进程的切换过程"><a href="#进程的切换过程" class="headerlink" title="进程的切换过程"></a>进程的切换过程</h2><p>用户态发生系统调用进入内核态</p><h2 id="进程和线程的区别"><a href="#进程和线程的区别" class="headerlink" title="进程和线程的区别"></a>进程和线程的区别</h2><ul><li>进程是资源分配的最小单位，线程是 CUP 调度的最小单位。</li><li>所有与进程相关的资源都被记录在 PCB 中。</li><li>进程是抢占处理机的调度单位，线程属于某个进程，共享其资源</li><li>线程只由堆栈寄存器、程序计数器和 TCB 组成</li><li>线程不能看做独立的应用，而进程可看做独立应用</li><li>进程有独立的地址空间，相互影响，线程只是进程的不同执行路径</li><li>线程没有独立的地址空间，多进程的程序比多线程程序健壮</li><li>进程的切换比线程切换开销大</li></ul><h2 id="进程的通信实现"><a href="#进程的通信实现" class="headerlink" title="进程的通信实现"></a>进程的通信实现</h2><ul><li><p>管道</p><p>半双工，速度慢，容量有限，只能父子间通信</p></li><li><p>命名管道</p></li><li><p>FIFO</p><p>任何进程间都能通信，速度慢</p></li><li><p>信号量</p><p>不能传递复杂消息，只能同步</p></li><li><p>共享内存</p><p>能够很容易控制容量，速度快</p></li></ul><h2 id="线程的通信实现"><a href="#线程的通信实现" class="headerlink" title="线程的通信实现"></a>线程的通信实现</h2><ul><li><p><strong>wait/notify机制</strong></p><p><strong>wait : </strong>让当前线程释放对象锁，并进入阻塞状态。</p><p><strong>notify :</strong>唤醒一个正在等待相应对象锁的线程，使其进入同步队列，以便在当前线程释放锁后竞争所，进而得到 CPU 的执行。在执行 notify 方法之后，当前线程并不能马上释放锁对象，呈 wait 状态的线程也并不能马上获取该对象锁，只有执行 notify 方法的线程退出 synchronized 代码块/方法后,当前线程才会释放锁，而呈 wait 状态的线程才会去竞争锁。</p><p><strong>notityAll :</strong>唤醒所有正在等待相应对象锁的线程。</p></li><li><p><strong>Condition</strong></p><p><strong>await</strong></p><p><strong>singal</strong></p><p><strong>singalAll</strong></p></li><li><p><strong>生产者消费者模型</strong></p></li><li><p><strong>管道 PipedOutStream/PipedInputStream</strong></p></li><li><p><strong>Join</strong></p><p>假如在main线程中调用thread.join方法，则main线程会等待thread线程执行完毕或者等待一定的时间。join 是调用 wait 方法实现，同样会让宿主线程交出 CPU 的执行权限，会让线程释放对一个对象持有的锁，如果调用了 join 方法，必须捕获 InterruptedException 异常或者将该异常向上层抛出。</p></li></ul>]]></content>
    
    <summary type="html">
    
      学习关于进程和线程的相关知识点
    
    </summary>
    
    
      <category term="操作系统" scheme="http://yoursite.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Http 和 Https的区别</title>
    <link href="http://yoursite.com/2019/05/09/Http-%E5%92%8C-Https%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
    <id>http://yoursite.com/2019/05/09/Http-和-Https的区别/</id>
    <published>2019-05-09T15:56:33.000Z</published>
    <updated>2019-08-11T15:19:16.021Z</updated>
    
    <content type="html"><![CDATA[<p>在开发中我们经常使用到 http 协议和 https 协议，那他们之间有什么区别呢？</p><p>他们的基本概念是什么呢？我们今天来学习一下。</p><a id="more"></a><h2 id="详细解析-HTTP-与-HTTPS-的区别"><a href="#详细解析-HTTP-与-HTTPS-的区别" class="headerlink" title="详细解析 HTTP 与 HTTPS 的区别"></a>详细解析 HTTP 与 HTTPS 的区别</h2><p>超文本传输协议HTTP协议被用于在Web浏览器和网站服务器之间传递信息，HTTP协议以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了Web浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此，HTTP协议不适合传输一些敏感信息，比如：信用卡号、密码等支付信息。为了解决 HTTP 协议的这一缺陷，需要使用另一种协议：安全套接字层超文本传输协议 HTTPS，为了数据传输的安全，HTTPS 在HTTP的基础上加入了 SSL 协议，SSL 依靠证书来验证服务器的身份，并为浏览器和服务器之间的通信加密。</p><h2 id="HTTP和HTTPS的基本概念"><a href="#HTTP和HTTPS的基本概念" class="headerlink" title="HTTP和HTTPS的基本概念"></a><strong>HTTP和HTTPS的基本概念</strong></h2><p><strong>HTTP</strong>：是互联网上应用最为广泛的一种网络协议，是一个客户端和服务器端请求和应答的标准（TCP），用于从WWW 服务器传输超文本到本地浏览器的传输协议，它可以使浏览器更加高效，使网络传输减少。</p><p><strong>HTTPS</strong>：是以安全为目标的 HTTP 通道，简单讲是 HTTP 的安全版，即 HTTP下 加入SSL层，HTTPS 的安全基础是SSL，因此加密的详细内容就需要SSL。</p><p><strong>HTTPS 协议的主要作用可以分为两种</strong>：</p><ul><li>建立一个信息安全通道，来保证数据传输的安全。</li><li>确认网站的真实性。</li></ul><h2 id="HTTP与HTTPS有什么区别"><a href="#HTTP与HTTPS有什么区别" class="headerlink" title="HTTP与HTTPS有什么区别"></a><strong>HTTP与HTTPS有什么区别</strong></h2><ul><li>https 协议需要到CA申请证书，一般免费证书较少，因而需要一定费用。</li><li>http 是超文本传输协议，信息是明文传输，https 则是具有安全性的 ssl 加密传输协议。</li><li>http 和 https 使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。</li><li>http 的连接很简单，是无状态的；HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比 http 协议安全。</li></ul><h2 id="数据传输安全的意思？"><a href="#数据传输安全的意思？" class="headerlink" title="数据传输安全的意思？"></a>数据传输安全的意思？</h2><ul><li>客户端和服务器之间的通信只能又自己看得懂，第三方拿到数据也看不懂这些信息的真实含义。</li><li>第三方虽然看不懂，但是可以对数据篡改，因此客户端和服务端必须有能力判断数据是否被修改过。</li><li>客户端必须避免中间人攻击，即除了真正的服务器，任何第三方都无法冒充服务器。</li></ul><h2 id="怎么加密信息？"><a href="#怎么加密信息？" class="headerlink" title="怎么加密信息？"></a>怎么加密信息？</h2><p>使用对称秘钥和非对称秘钥进行加密，对称秘钥是加密和解密都用相同的秘钥进行。非对称秘钥有两个秘钥，一个公钥和一个私钥。公钥加密的内容只有通过私钥才能解密，私钥加密的内容只有通过公钥进行解密。使用对称加密一般比非对称加密快得多，对服务器的运算压力也小。</p><h2 id="对称秘钥怎么传输"><a href="#对称秘钥怎么传输" class="headerlink" title="对称秘钥怎么传输?"></a>对称秘钥怎么传输?</h2><p>服务器明文传输对称秘钥是不安去的，如果监听者拿到对称秘钥，以后的通信内容就被破解了。所以不能明文传输对称秘钥，而且不能用一个新的对称秘钥来加密原来的对称秘钥，否则新的对称秘钥同样无法传输，就是鸡生蛋，蛋生鸡的驳论。</p><p>这里我们采用非对称加密的方式，非对称加密的特性决定了服务器用私钥加密的内容并不是真正的加密，因为公钥所有人都有，所以服务器的密文能被所有人解析，但是私钥只掌握在服务器手上，这就带来了两个好的优势：</p><ul><li>服务器下发的内容不能被伪造，因为别人都没有私钥，只有服务器有，所以无法加密。强行加密的后果是客户端使用公钥都无法完成解密。</li><li>任何人用公钥加密的内容都是绝对安全的，因为私钥只有服务端有，也就是只有真正的服务器可以看到加密的原文</li></ul><p>所以传输对称秘钥的问题就迎刃而解了：秘钥不是由服务器下发的，而是由客户端生成并主动高数服务器。所以当引入非对称加密后，HTTPS的握手流程依然是两部，不过细节略有变化：</p><p>​    客户端：你好，我要发起一个HTTPS的请求，这是我的秘钥（用公钥加密后的）</p><p>​    服务端：好的，我知道你的秘钥了，后续就用它来传输。</p><h2 id="公钥怎么传输？"><a href="#公钥怎么传输？" class="headerlink" title="公钥怎么传输？"></a>公钥怎么传输？</h2><p>对公钥进行加密，每一个HTTPS服务器都必须去专门的证书机构注册一个证书，证书中存储了用权威机构私钥加密的公钥。这样客户端用权威机构的公钥解密就可以了。</p><p>现在HTTPS协议握手阶段变成四步：</p><ol><li>客户端：你好，我要发起一个HTTPS请求，请给我公钥</li><li>服务器：好的，这是我的证书，里面有加密后的公钥</li><li>客户端：解密成功以后告诉服务器，这是我的对称秘钥</li><li>服务器：好的，我知道了你的秘钥了，后续就用它来传输吧。</li></ol><h2 id="那么权威机构的公钥怎么传输呢？"><a href="#那么权威机构的公钥怎么传输呢？" class="headerlink" title="那么权威机构的公钥怎么传输呢？"></a>那么权威机构的公钥怎么传输呢？</h2><p>这个公钥不用传输，会直接内置在各大操作系统或者浏览器的出厂设置里。之所以不把每个服务器的公钥内置在电脑里，一方面服务器太多，存不过来。另一方面操作系统也不信任你，凭什么你说你这个就是百度的证书呢。所以各个公司先去权威机构认证，申请证书，然后操作系统只会存储权威机构的公钥。因为权威机构数量有限，所以操作系统厂商相对来说容易管理。如果这个权威机构不够权威，胡乱发证书，就会取消他的资格，比如可怜的沃通。</p><h2 id="怎么知道证书没有被篡改？"><a href="#怎么知道证书没有被篡改？" class="headerlink" title="怎么知道证书没有被篡改？"></a>怎么知道证书没有被篡改？</h2><p>将信息哈希值随着信息一起传递。为了保证证书没有篡改，我们可以在传递证书的同时传递的哈希值。由于第三者无法解析数据，只能胡乱改，那么修改后的数据在解密后，就不能通过哈希。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在开发中我们经常使用到 http 协议和 https 协议，那他们之间有什么区别呢？&lt;/p&gt;
&lt;p&gt;他们的基本概念是什么呢？我们今天来学习一下。&lt;/p&gt;
    
    </summary>
    
    
      <category term="网络" scheme="http://yoursite.com/tags/%E7%BD%91%E7%BB%9C/"/>
    
  </entry>
  
  <entry>
    <title>线程池使用总结</title>
    <link href="http://yoursite.com/2019/05/09/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BD%BF%E7%94%A8%E6%80%BB%E7%BB%93/"/>
    <id>http://yoursite.com/2019/05/09/线程池使用总结/</id>
    <published>2019-05-09T14:00:43.000Z</published>
    <updated>2019-08-11T05:25:14.657Z</updated>
    
    <content type="html"><![CDATA[<h2 id="线程池的好处"><a href="#线程池的好处" class="headerlink" title="线程池的好处"></a>线程池的好处</h2><h2 id="线程池"><a href="#线程池" class="headerlink" title="线程池"></a>线程池</h2><p><img src="/2019/05/09/线程池使用总结/1557327261076.png" alt></p><h2 id="线程池的执行流程"><a href="#线程池的执行流程" class="headerlink" title="线程池的执行流程"></a>线程池的执行流程</h2><p><img src="/2019/05/09/线程池使用总结/1557327546254.png" alt></p><h2 id="线程池的创建"><a href="#线程池的创建" class="headerlink" title="线程池的创建"></a>线程池的创建</h2><p><img src="/2019/05/09/线程池使用总结/1557327451978.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;线程池的好处&quot;&gt;&lt;a href=&quot;#线程池的好处&quot; class=&quot;headerlink&quot; title=&quot;线程池的好处&quot;&gt;&lt;/a&gt;线程池的好处&lt;/h2&gt;&lt;h2 id=&quot;线程池&quot;&gt;&lt;a href=&quot;#线程池&quot; class=&quot;headerlink&quot; title=&quot;线程池
      
    
    </summary>
    
    
      <category term="thread" scheme="http://yoursite.com/tags/thread/"/>
    
  </entry>
  
  <entry>
    <title>spring回滚事务的处理思路</title>
    <link href="http://yoursite.com/2019/05/09/spring%E5%9B%9E%E6%BB%9A%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%A4%84%E7%90%86%E6%80%9D%E8%B7%AF/"/>
    <id>http://yoursite.com/2019/05/09/spring回滚事务的处理思路/</id>
    <published>2019-05-09T13:48:02.000Z</published>
    <updated>2019-08-11T15:16:05.197Z</updated>
    
    <content type="html"><![CDATA[<p>我们在使用中经常使用 spring，但是我们是否真正的理解当事务发生回滚的时候spring 是怎么给我处理的吗？是否会回滚呢，现在让我们来一起看看吧。</p><a id="more"></a><h2 id="spring-try-…-catch-事务不回滚的处理思路"><a href="#spring-try-…-catch-事务不回滚的处理思路" class="headerlink" title="spring try {…} catch {} 事务不回滚的处理思路"></a>spring try {…} catch {} 事务不回滚的处理思路</h2><p>当希望在某个方法中添加事务时，我们常常在方法头上添加@Transactional注解</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/payment"</span>, method = RequestMethod.POST, produces = MediaType.APPLICATION_JSON_VALUE)</span><br><span class="line"><span class="meta">@Transactional</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Payment <span class="title">paymentJson</span><span class="params">(@RequestBody PaymentRequestInfo entity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//method</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>容易让人忽略的是：方法上未加任何属性的 @Transactional 注解只能在抛出 RuntimeException 或者 Error 时才会触发事务的回滚，常见的 非RuntimeException 是不会触发事务的回滚的。</p><p>如果要在抛出 非RuntimeException时也触发回滚机制，需要我们在注解上添加 rollbackFor = { Exception.class }属性。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/payment"</span>, method = RequestMethod.POST, produces = MediaType.APPLICATION_JSON_VALUE)</span><br><span class="line"><span class="meta">@Transactional</span>(rollbackFor = &#123; Exception.class &#125;)</span><br><span class="line"><span class="function"><span class="keyword">public</span> Payment <span class="title">paymentJson</span><span class="params">(@RequestBody PaymentRequestInfo entity)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//method</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当然，上面事务回滚的前提是添加 @Transactional 注解的方法中不含有 try{…}catch{…} 异常，使得程序运行过程中出现异常能顺利抛出，从而触发事务回滚。</p><p>在实际开发中，我们往往需要在方法中进行异常的捕获，从而对异常进行判断，为客户端返回提示信息。但是此时由于异常的被捕获，导致事务的回滚没有被触发，导致事务的失败。</p><p>下面提供几种解决方法：</p><h3 id="1-使用-Transactional注解，抛出-Transactional注解默认识别的RuntimeException"><a href="#1-使用-Transactional注解，抛出-Transactional注解默认识别的RuntimeException" class="headerlink" title="1. 使用@Transactional注解，抛出@Transactional注解默认识别的RuntimeException"></a>1. 使用@Transactional注解，抛出@Transactional注解默认识别的RuntimeException</h3><p>方法上使用@Transactional注解，在捕获到异常时在catch语句中抛出RuntimeException。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/payment"</span>, method = RequestMethod.POST, produces = MediaType.APPLICATION_JSON_VALUE)</span><br><span class="line"><span class="meta">@Transactional</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Payment <span class="title">paymentJson</span><span class="params">(@RequestBody PaymentRequestInfo entity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        </span><br><span class="line">    &#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">        <span class="comment">// 处理返回消息</span></span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="2-使用-Transactional-rollbackFor-Exception-class-，抛出捕获的非RuntimeException异常"><a href="#2-使用-Transactional-rollbackFor-Exception-class-，抛出捕获的非RuntimeException异常" class="headerlink" title="2. 使用@Transactional(rollbackFor = { Exception.class })，抛出捕获的非RuntimeException异常"></a>2. 使用@Transactional(rollbackFor = { Exception.class })，抛出捕获的非RuntimeException异常</h3><p>方法上使用@Transactional(rollbackFor = { Exception.class })注解声明事务回滚级别，在捕获到异常时在catch语句中直接抛出所捕获的异常。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/payment"</span>, method = RequestMethod.POST, produces = MediaType.APPLICATION_JSON_VALUE)</span><br><span class="line"><span class="meta">@Transactional</span>(rollbackFor = &#123; Exception.class &#125;)</span><br><span class="line"><span class="function"><span class="keyword">public</span> Payment <span class="title">paymentJson</span><span class="params">(@RequestBody PaymentRequestInfo entity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">    &#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">        <span class="comment">// 处理返回消息</span></span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-手动回滚"><a href="#3-手动回滚" class="headerlink" title="3. 手动回滚"></a>3. 手动回滚</h3><p>上面两个在catch{…}中抛出异常的方法都有个不足之处，就是不能在catch{…}中存在return子句，所以设置手动回滚，当捕获到异常时，手动回滚，同时返回前台提示信息。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ResponseBody</span></span><br><span class="line"><span class="meta">@RequestMapping</span>(value = <span class="string">"/payment"</span>, method = RequestMethod.POST, produces = MediaType.APPLICATION_JSON_VALUE)</span><br><span class="line"><span class="meta">@Transactional</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Payment <span class="title">paymentJson</span><span class="params">(@RequestBody PaymentRequestInfo entity)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">    &#125; <span class="keyword">catch</span>(Exception e) &#123;</span><br><span class="line">        <span class="comment">// 手动回滚事务</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我们在使用中经常使用 spring，但是我们是否真正的理解当事务发生回滚的时候spring 是怎么给我处理的吗？是否会回滚呢，现在让我们来一起看看吧。&lt;/p&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>常见问题总结</title>
    <link href="http://yoursite.com/2019/05/09/MQ%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/"/>
    <id>http://yoursite.com/2019/05/09/MQ常见问题/</id>
    <published>2019-05-09T12:12:15.000Z</published>
    <updated>2019-08-11T05:25:14.656Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MQ常见问题"><a href="#MQ常见问题" class="headerlink" title="MQ常见问题"></a>MQ常见问题</h1><p>消息队列核心解决的问题主要是：异步、解耦、消息切峰。异步、解耦、消峰填谷这是消息队列最大的优点，除了这些消息队列还可以会解决一些我们特殊业务场景的问题。但是缺点主要在于系统的可用性、复杂性、一致性问题，引入消息队列后，需要考虑MQ的可用性，万一MQ崩溃了岂不是要爆炸？而且复杂性明显提高了，需要考虑一些消息队列的常见问题和解决方案，还有就是一致性问题，一条消息由多个消费者消费，万一有一个消费者消费失败了，就会导致数据不一致。</p><h2 id="RabbitMQ"><a href="#RabbitMQ" class="headerlink" title="RabbitMQ"></a>RabbitMQ</h2><ul><li>单机吞吐量：万级别</li><li>失效性：微秒级别</li><li>可用性：基于主从架构</li></ul><p>RabbitMQ现在使用的较为多一些，社区活跃度也很高，功能也很强大，官方还提供了管理的web界面，性能也很好，但是RabbitMQ性能好的主要原因是因为使用erlang语言开发的，erlang语言貌似天生性能好，但对于我们java开发者来说，源码基本看不懂，更别提深入的研究了，不过spring推出了rabbit的支持，貌似还比较好用，比自己去封装实现并且去处理一些问题的要好多了。</p><h2 id="RabbitMQ-模式"><a href="#RabbitMQ-模式" class="headerlink" title="RabbitMQ 模式"></a>RabbitMQ 模式</h2><ul><li><p>单机模式</p><p>单机模式通常是用来进行测试和开发的场景，测试一般是否能正确的处理数据，线上环境没人去用单机模式，风险大。</p></li><li><p>普通集群模式</p><p>普通集群模式就是启动多个 RabbitMQ 实例，在你创建queue只会放在一个 RabbitMQ上，但是每个实例都同步 queue 的元数据，在消费的时候，如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，后者有数据拉取的开销，前者导致单实例性能瓶颈。而且如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让RabbitMQ落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作</p></li><li><p>镜像集群模式</p><p>镜像集群模式是所谓的RabbitMQ的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。</p><p>优点在于你任何一个实例宕机了，没事儿，别的实例都可以用。缺点在于性能开销太大和扩展性很低，同步所有实例，这会导致网络带宽和压力很重，而且扩展性很低，每增加一个实例都会去包含已有的queue的所有数据，并没有办法线性扩展queue。</p><p>开启镜像集群模式可以去RabbitMQ的管理控制台去增加一个策略，指定要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p></li></ul><h2 id="如何保证消息的幂等性"><a href="#如何保证消息的幂等性" class="headerlink" title="如何保证消息的幂等性"></a>如何保证消息的幂等性</h2><p>消息重复消费的原因主要是在与回馈机制，在某些场景中我们采用回馈机制不同，原因也不同，比如消费者消费完成消息之后回复 ack ，但是刚消费完成还没有来的及提交，系统就重新启动。这时重新启动就会pull 消息的时候没有提高 ack ，消息还是上次的消息。</p><p>那么如何怎么来保证消息消费的幂等性呢？实际上我们只要保证多条相同的数据过来的时候只处理一条或者说多条处理和处理一条造成的结果相同即可，但是具体怎么做要根据业务需求来定，例如入库消息，先查一下消息是否已经入库啊或者说搞个唯一约束啊什么的，还有一些是天生保证幂等性就根本不用去管，例如redis就是天然幂等性。</p><p>还有一个问题，消费者消费消息的时候在某些场景下要放过消费不了的消息，遇到消费不了的消息通过日志记录一下或者搞个什么措施以后再来处理，但是一定要放过消息，因为在某些场景下例如spring-rabbitmq的默认回馈策略是出现异常就没有提交ack，导致了一直在重发那条消费异常的消息，而且一直还消费不了，这就尴尬了，后果你会懂的。</p><h2 id="消息遗漏"><a href="#消息遗漏" class="headerlink" title="消息遗漏"></a>消息遗漏</h2><p><strong>1）生产者弄丢了数据</strong><br>　　生产者将数据发送到RabbitMQ的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。此时可以选择用RabbitMQ提供的事务功能，就是生产者发送数据之前开启RabbitMQ事务（channel.txSelect），然后发送消息，如果消息没有成功被RabbitMQ接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，RabbitMQ事务机制一搞，基本上吞吐量会下来，因为太耗性能。</p><p>　　所以一般来说，如果你要确保说写RabbitMQ的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了RabbitMQ中，RabbitMQ会给你回传一个ack消息，告诉你说这个消息ok了。如果RabbitMQ没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p><p>　　事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息RabbitMQ接收了之后会异步回调你一个接口通知你这个消息接收到了。</p><p>　　所以一般在生产者这块避免数据丢失，都是用confirm机制的。</p><p><strong>（2）RabbitMQ弄丢了数据</strong></p><p>　　就是RabbitMQ自己弄丢了数据，这个你必须开启RabbitMQ的持久化，就是消息写入之后会持久化到磁盘，哪怕是RabbitMQ自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，RabbitMQ还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。</p><h5 id="设置持久化有两个步骤"><a href="#设置持久化有两个步骤" class="headerlink" title="设置持久化有两个步骤"></a>设置持久化有两个步骤</h5><p>第一个是创建queue的时候将其设置为持久化的，这样就可以保证RabbitMQ持久化queue的元数据，但是不会持久化queue里的数据；</p><p>第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时RabbitMQ就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，RabbitMQ哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。</p><p>而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，RabbitMQ挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。</p><p>哪怕是你给RabbitMQ开启了持久化机制，也有一种可能，就是这个消息写到了RabbitMQ中，但是还没来得及持久化到磁盘上，结果不巧，此时RabbitMQ挂了，就会导致内存里的一点点数据会丢失。</p><p><strong>（3）消费端弄丢了数据</strong></p><p>　　RabbitMQ如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，RabbitMQ认为你都消费了，这数据就丢了。</p><p>　　这个时候得用RabbitMQ提供的ack机制，简单来说，就是你关闭RabbitMQ自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，在程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那RabbitMQ就认为你还没处理完，这个时候RabbitMQ会把这个消费分配给别的consumer去处理，消息是不会丢的。</p><p>在发送消息的时候，接受时记录 DB 日志，定时轮询 DB 日志，查明那些发送的消息没有成功消费，启动重新发送消息机制。</p><h2 id="消息顺序"><a href="#消息顺序" class="headerlink" title="消息顺序"></a>消息顺序</h2><p><strong>场景： 比如下单操作，下单成功后，会发布创建订单和减库存的消息，但扣库存消息执行会先于创建订单的消息，也就说前者执行成功之后，才能执行后者。</strong></p><p>MQ 层面支持消息的顺序处理开销太大了，为了极少量的需求，增加了整体上的复杂性。应该尽可能的在应用层面进行处理。</p><p>解决方式如下：</p><ol><li>同步执行，当一个消息执行之后，再发送下一个消息。</li><li>rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理。</li></ol><h2 id="消息重复"><a href="#消息重复" class="headerlink" title="消息重复"></a>消息重复</h2><p>如果消费端接受到两个一样的消息，应该如何处理呢？</p><ol><li>消费端处理消息的业务逻辑应该保持幂等性。</li><li>保证每条消息都有唯一标号，首先检查执行成功的日志中是否存有该消息的 ID 如果没有则执行，如果已经存在则丢弃消息。如果在消息系统中实现，会对消息系统的吞吐量造成影响。所以还是在业务端进行去重处理。</li></ol><h2 id="事务消息"><a href="#事务消息" class="headerlink" title="事务消息"></a>事务消息</h2><p> 具体来说，就是把消息的发送分成了2个阶段：Prepare阶段和确认阶段。</p><p>具体来说，上面的2个步骤，被分解成3个步骤：<br>(1) 发送Prepared消息<br>(2) update DB<br>(3) 根据update DB结果成功或失败，Confirm 或者取消 Prepared 消息。</p><p>可能有人会问了，前2步执行成功了，最后1步失败了怎么办？这里就涉及到了RocketMQ的关键点：RabbitMQ 会定期（默认是1分钟）扫描所有的Prepared消息，询问发送方，到底是要确认这条消息发出去？还是取消此条消息？</p><h2 id="消息阻塞"><a href="#消息阻塞" class="headerlink" title="消息阻塞"></a>消息阻塞</h2><p><strong>上千万条消息在 mq 里积压了几个小时了还没解决</strong> </p><p>紧急扩容</p><p>1）先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉<br>2）新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量<br>3）然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，<br>消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue<br>4）接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据<br>5）这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据<br>6）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息</p><h2 id="消息队列过期失效问题"><a href="#消息队列过期失效问题" class="headerlink" title="消息队列过期失效问题"></a>消息队列过期失效问题</h2><p>　假设你用的是rabbitmq，rabbitmq是可以设置过期时间的，就是TTL，如果消息在queue中积压超过一定的时间就会被rabbitmq给清理掉，这个数据就没了。晚上12点以后，用户都睡觉了。</p><p>　　这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入mq里面去，把白天丢的数据给他补回来。也只能是这样了。</p><p>　　假设1万个订单积压在mq里面，没有处理，其中1000个订单都丢了，你只能手动写程序把那1000个订单给查出来，手动发到mq里去再补一次。</p><h2 id="消息队列满"><a href="#消息队列满" class="headerlink" title="消息队列满"></a>消息队列满</h2><p>丢弃，晚上补数据</p>]]></content>
    
    <summary type="html">
    
      MQ 生产上遇到的一些问题和解决办法进行总结
    
    </summary>
    
    
      <category term="MQ" scheme="http://yoursite.com/tags/MQ/"/>
    
  </entry>
  
</feed>
