<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小白君的博客</title>
  
  <subtitle>凡事必先骑上虎背</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-08-29T15:51:00.070Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Ma Xu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Redis主从复制过程</title>
    <link href="http://yoursite.com/2019/08/29/Redis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E8%BF%87%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/08/29/Redis主从复制过程/</id>
    <published>2019-08-29T10:54:06.000Z</published>
    <updated>2019-08-29T15:51:00.070Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Mybatis防止Sql注入</title>
    <link href="http://yoursite.com/2019/08/29/Mybatis%E9%98%B2%E6%AD%A2Sql%E6%B3%A8%E5%85%A5/"/>
    <id>http://yoursite.com/2019/08/29/Mybatis防止Sql注入/</id>
    <published>2019-08-29T10:52:34.000Z</published>
    <updated>2019-08-29T15:51:00.069Z</updated>
    
    <content type="html"><![CDATA[<p>Mybatsi 使用 <strong># </strong>防止 SQL 注入，它将所有传入的参数当作一个字符串来处理，<strong>$</strong> 则将传入的参数拼接到 SQL 上执行，一般用于表名和字段名的参数，<strong>$</strong> 所对应的参数应该由服务端提供，前端可以用参数选择，避免 SQL 注入的风险。</p><blockquote><p>额外我们还可以通过使用存储过程防止 SQL 注入</p></blockquote><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>为什么 <strong>#</strong> 可以防止 SQL 注入呢？让我们追踪一下源码。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ClassDao</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 测试 # 和 $ 符号区别</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> tableName 表名</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> id  主键</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="meta">@Select</span>(<span class="string">"select * from $&#123;tableName&#125; where class_id = #&#123;id&#125;"</span>)</span><br><span class="line"><span class="function">ClassInfo <span class="title">getByTableNameAndId</span><span class="params">(@Param(<span class="string">"tableName"</span>)</span> String tableName,@<span class="title">Param</span><span class="params">(<span class="string">"id"</span>)</span>Integer id)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="源码分析"><a href="#源码分析" class="headerlink" title="源码分析"></a>源码分析</h2><ol><li>Mybatis 执行 入口是 DefaultSqlSession.selectOne(）方法。我们Debug 启动 testMybatis（）方法，并在 DefaultSqlSession.selectOne()添加断点，一行行执行Mybatis 代码：</li></ol><p><img src="/2019/08/29/Mybatis防止Sql注入/Users/maxu/blog/source/_posts/Mybatis防止Sql注入/image-20190829202052565.png" alt="image-20190829202052565"></p><ol start="2"><li>一步步向下走，当走到代码： org.apache.ibatis.executor.statement.PreparedStatementHandler#query方法时，可以看到 PreparedStatement 相信大家对这个应该不会陌生，预编译Sql并通过占位符的方式放置参数，现在 我们对比一下我们在 Dao 中的 sql ： select * from ${tableName} where class_id = #{id}</li></ol><p><img src="/2019/08/29/Mybatis防止Sql注入/Users/maxu/blog/source/_posts/Mybatis防止Sql注入/image-20190829202206705.png" alt="image-20190829202206705"></p><ol start="3"><li>如图所示，我们会发现， Mybatis 已经将 sql中 ${tableName} 替换成了 tb_class ，#{id} 也已经变成了 占位符 ？，生成了 Sql ： select * from tb_class where class_id = ?。这已经是一目了然了，Mybaitis 封装了JDBC ,执行时会将我们注解 或 Mapper 中的 Sql 和参数进行处理，并交给 PreparedStatement 来执行。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Mybatsi 使用 &lt;strong&gt;# &lt;/strong&gt;防止 SQL 注入，它将所有传入的参数当作一个字符串来处理，&lt;strong&gt;$&lt;/strong&gt; 则将传入的参数拼接到 SQL 上执行，一般用于表名和字段名的参数，&lt;strong&gt;$&lt;/strong&gt; 所对应的参数
      
    
    </summary>
    
    
      <category term="Mybatis" scheme="http://yoursite.com/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>$与#</title>
    <link href="http://yoursite.com/2019/08/29/%E4%B8%8E/"/>
    <id>http://yoursite.com/2019/08/29/与/</id>
    <published>2019-08-29T10:51:51.000Z</published>
    <updated>2019-08-29T15:51:00.077Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>CAS实现原理</title>
    <link href="http://yoursite.com/2019/08/29/CAS%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <id>http://yoursite.com/2019/08/29/CAS实现原理/</id>
    <published>2019-08-29T10:51:25.000Z</published>
    <updated>2019-08-29T15:51:00.065Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>操作系统内存管理</title>
    <link href="http://yoursite.com/2019/08/29/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
    <id>http://yoursite.com/2019/08/29/操作系统内存管理/</id>
    <published>2019-08-29T10:51:15.000Z</published>
    <updated>2019-08-29T15:51:00.087Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Java线程与操作系统线程的关系</title>
    <link href="http://yoursite.com/2019/08/29/Java%E7%BA%BF%E7%A8%8B%E4%B8%8E%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%85%B3%E7%B3%BB/"/>
    <id>http://yoursite.com/2019/08/29/Java线程与操作系统线程的关系/</id>
    <published>2019-08-28T16:02:13.000Z</published>
    <updated>2019-08-29T15:51:00.067Z</updated>
    
    <content type="html"><![CDATA[<p>Linux从内核2.6开始使用NPTL （Native POSIX Thread Library）支持，但这时线程本质上还轻量级进程。 </p><p>　　Java里的线程是由JVM来管理的，它如何对应到操作系统的线程是由JVM的实现来确定的。Linux 2.6上的HotSpot使用了NPTL机制，<strong>JVM线程跟内核轻量级进程有一一对应的关系</strong>。线程的调度完全交给了操作系统内核，当然jvm还保留一些策略足以影响到其内部的线程调度，举个例子，在linux下，只要一个Thread.run就会调用一个fork产生一个线程。</p><p>　　Java线程在Windows及Linux平台上的实现方式，现在看来，是内核线程的实现方式。<strong>这种方式实现的线程，是直接由操作系统内核支持的——由内核完成线程切换，内核通过操纵调度器（Thread Scheduler）实现线程调度，并将线程任务反映到各个处理器上。</strong>内核线程是内核的一个分身。程序一般不直接使用该内核线程，而是使用其高级接口，即轻量级进程（LWP），也即线程。这看起来可能很拗口。看图：</p><p><img src="/2019/08/29/Java线程与操作系统线程的关系/image-20190829000505977.png" alt="image-20190829000505977"></p><p>说明：KLT即内核线程Kernel Thread，是“内核分身”。每一个KLT对应到进程P中的某一个轻量级进程LWP（也即线程），期间要经过用户态、内核态的切换，并在Thread Scheduler 下反应到处理器CPU上。）</p><p>这种线程实现的方式也有它的缺陷：在程序面上使用内核线程，必然在操作系统上多次来回切换用户态及内核态；另外，因为是一对一的线程模型，LWP的支持数是有限的。</p><p>　　对于一个大型程序，我们可以<strong>开辟的线程数量至少等于运行机器的cpu内核数量</strong>。java程序里我们可以通过下面的一行代码得到这个数量：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Runtime.getRuntime().availableProcessors();</span><br></pre></td></tr></table></figure><p>所以最小线程数量即时cpu内核数量。如果所有的任务都是计算密集型的，这个最小线程数量就是我们需要的线程数。开辟更多的线程只会影响程序的性能，因为线程之间的切换工作，会消耗额外的资源。如果任务是IO密集型的任务，我们可以开辟更多的线程执行任务。当一个任务执行IO操作的时候，线程将会被阻塞，处理器立刻会切换到另外一个合适的线程去执行。如果我们只拥有与内核数量一样多的线程，即使我们有任务要执行，他们也不能执行，因为处理器没有可以用来调度的线程。</p><p>​       <strong>如果线程有50%的时间被阻塞，线程的数量就应该是内核数量的2倍。</strong>如果更少的比例被阻塞，那么它们就是计算密集型的，则需要开辟较少的线程。如果有更多的时间被阻塞，那么就是IO密集型的程序，则可以开辟更多的线程。于是我们可以得到下面的线程数量计算公式：线程数量=内核数量 / （1 - 阻塞率）</p><p>　　我们可以通过相应的分析工具或者java的management包来得到阻塞率的数值。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Linux从内核2.6开始使用NPTL （Native POSIX Thread Library）支持，但这时线程本质上还轻量级进程。 &lt;/p&gt;
&lt;p&gt;　　Java里的线程是由JVM来管理的，它如何对应到操作系统的线程是由JVM的实现来确定的。Linux 2.6上的HotS
      
    
    </summary>
    
    
      <category term="操作系统" scheme="http://yoursite.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>orderby工作流程</title>
    <link href="http://yoursite.com/2019/08/27/orderby%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B/"/>
    <id>http://yoursite.com/2019/08/27/orderby工作流程/</id>
    <published>2019-08-27T08:10:24.000Z</published>
    <updated>2019-08-29T15:51:00.074Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>唯一索引和普通索引</title>
    <link href="http://yoursite.com/2019/08/27/%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E5%92%8C%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95/"/>
    <id>http://yoursite.com/2019/08/27/唯一索引和普通索引/</id>
    <published>2019-08-27T07:41:38.000Z</published>
    <updated>2019-08-29T15:51:00.088Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>进程间通信方式</title>
    <link href="http://yoursite.com/2019/08/26/%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E6%96%B9%E5%BC%8F/"/>
    <id>http://yoursite.com/2019/08/26/进程间通信方式/</id>
    <published>2019-08-26T04:04:51.000Z</published>
    <updated>2019-08-29T15:51:00.086Z</updated>
    
    <content type="html"><![CDATA[<h1 id="进程间通信（IPC）介绍"><a href="#进程间通信（IPC）介绍" class="headerlink" title="进程间通信（IPC）介绍"></a>进程间通信（IPC）介绍</h1><p>进程间通信（IPC，InterProcess Communication）是指在不同进程之间传播或交换信息。</p><p>IPC的方式通常有管道（包括无名管道和命名管道）、消息队列、信号量、共享存储、Socket、Streams等。其中 Socket和Streams支持不同主机上的两个进程IPC。</p><p>以Linux中的C语言编程为例。</p><h2 id="管道"><a href="#管道" class="headerlink" title="管道"></a>管道</h2><p>管道，通常指无名管道，是 UNIX 系统IPC最古老的形式。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li>它是半双工的，具有固定的读端和写端。</li><li>它只能用于具有<strong>亲缘关系</strong>的进程之间的通信（也是父子进程或者兄弟进程之间）。</li><li>它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。</li></ul><h3 id="原型"><a href="#原型" class="headerlink" title="原型"></a>原型</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span> <span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="number">2</span> <span class="function"><span class="keyword">int</span> <span class="title">pipe</span><span class="params">(<span class="keyword">int</span> fd[<span class="number">2</span>])</span></span>;    <span class="comment">// 返回值：若成功返回0，失败返回-1</span></span><br></pre></td></tr></table></figure><p>当一个管道建立时，它会创建两个文件描述符：fd[0]为读而打开，fd[1]为写而打开。如下图：</p><p><img src="/2019/08/26/进程间通信方式/image-20190826141126633.png" alt="image-20190826141126633"></p><p>要关闭管道只需将这两个文件描述符关闭即可。</p><h3 id="举例"><a href="#举例" class="headerlink" title="举例"></a>举例</h3><p>单个进程中的管道几乎没有任何用处。所以，通常调用 pipe 的进程接着调用 fork，这样就创建了父进程与子进程之间的 IPC 通道。如下图所示：</p><p><img src="/2019/08/26/进程间通信方式/Users/maxu/hexo/source/_posts/进程间通信方式/image-20190826141404697.png" alt="image-20190826141404697"></p><p>Fork 之后的半双工管道</p><p><img src="/2019/08/26/进程间通信方式/Users/maxu/hexo/source/_posts/进程间通信方式/image-20190826141436913.png" alt="image-20190826141436913"></p><p>从父进程到子进程的管道</p><p>若要数据流从父进程流向子进程，则关闭父进程的读端（fd[0]）与子进程的写端（fd[1]）；反之，则可以使数据流从子进程流向父进程。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;进程间通信（IPC）介绍&quot;&gt;&lt;a href=&quot;#进程间通信（IPC）介绍&quot; class=&quot;headerlink&quot; title=&quot;进程间通信（IPC）介绍&quot;&gt;&lt;/a&gt;进程间通信（IPC）介绍&lt;/h1&gt;&lt;p&gt;进程间通信（IPC，InterProcess Communi
      
    
    </summary>
    
    
      <category term="操作系统" scheme="http://yoursite.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>Mybatis缓存</title>
    <link href="http://yoursite.com/2019/08/20/Mybatis%E7%BC%93%E5%AD%98/"/>
    <id>http://yoursite.com/2019/08/20/Mybatis缓存/</id>
    <published>2019-08-20T08:37:26.000Z</published>
    <updated>2019-08-29T15:51:00.069Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一级缓存"><a href="#一级缓存" class="headerlink" title="一级缓存"></a>一级缓存</h2><p>在应用运行过程中，我们有可能在一次数据库会话中，执行多次查询条件完全相同的SQL，MyBatis提供了一级缓存的方案优化这部分场景，如果是相同的SQL语句，会优先命中一级缓存，避免直接对数据库进行查询，提高性能。具体执行过程如下图所示。</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190820165449480.png" alt></p><p>每个SqlSession中持有了Executor，每个Executor中有一个LocalCache。当用户发起查询时，MyBatis根据当前执行的语句生成<code>MappedStatement</code>，在Local Cache进行查询，如果缓存命中的话，直接返回结果给用户，如果缓存没有命中的话，查询数据库，结果写入<code>Local Cache</code>，最后返回结果给用户。具体实现类的类关系图如下图所示。</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190820170058613.png" alt="image-20190820170058613"></p><h3 id="一级缓存配置"><a href="#一级缓存配置" class="headerlink" title="一级缓存配置"></a>一级缓存配置</h3><p>我们来看看如何使用MyBatis一级缓存。开发者只需在MyBatis的配置文件中，添加如下语句，就可以使用一级缓存。共有两个选项，<code>SESSION</code>或者<code>STATEMENT</code>，默认是<code>SESSION</code>级别，即在一个MyBatis会话中执行的所有语句，都会共享这一个缓存。一种是<code>STATEMENT</code>级别，可以理解为缓存只对当前执行的这一个<code>Statement</code>有效。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">setting</span> <span class="attr">name</span>=<span class="string">"localCacheScope"</span> <span class="attr">value</span>=<span class="string">"SESSION"</span>/&gt;</span></span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li>MyBatis一级缓存的生命周期和SqlSession一致。</li><li>MyBatis一级缓存内部设计简单，只是一个没有容量限定的HashMap，在缓存的功能性上有所欠缺。</li><li>MyBatis的一级缓存最大范围是SqlSession内部，有多个SqlSession或者分布式的环境下，数据库写操作会引起脏数据，建议设定缓存级别为Statement。</li></ol><h2 id="二级缓存"><a href="#二级缓存" class="headerlink" title="二级缓存"></a>二级缓存</h2><p>在上文中提到的一级缓存中，其最大的共享范围就是一个SqlSession内部，如果多个SqlSession之间需要共享缓存，则需要使用到二级缓存。开启二级缓存后，会使用CachingExecutor装饰Executor，进入一级缓存的查询流程前，先在CachingExecutor进行二级缓存的查询，具体的工作流程如下所示。</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190820171955509.png" alt="image-20190820171955509"></p><p>二级缓存开启后，同一个namespace下的所有操作语句，都影响着同一个Cache，即二级缓存被多个SqlSession共享，是一个全局的变量。</p><p>当开启缓存后，数据的查询执行的流程就是 二级缓存 -&gt; 一级缓存 -&gt; 数据库。</p><h3 id="二级缓存配置"><a href="#二级缓存配置" class="headerlink" title="二级缓存配置"></a>二级缓存配置</h3><p>要正确的使用二级缓存，需完成如下配置的。</p><ol><li>在MyBatis的配置文件中开启二级缓存。</li></ol><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">setting</span> <span class="attr">name</span>=<span class="string">"cacheEnabled"</span> <span class="attr">value</span>=<span class="string">"true"</span>/&gt;</span></span><br></pre></td></tr></table></figure><ol><li>在MyBatis的映射XML中配置cache或者 cache-ref 。</li></ol><p>cache标签用于声明这个namespace使用二级缓存，并且可以自定义配置。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">cache</span>/&gt;</span></span><br></pre></td></tr></table></figure><ul><li><code>type</code>：cache使用的类型，默认是<code>PerpetualCache</code>，这在一级缓存中提到过。</li><li><code>eviction</code>： 定义回收的策略，常见的有FIFO，LRU。</li><li><code>flushInterval</code>： 配置一定时间自动刷新缓存，单位是毫秒。</li><li><code>size</code>： 最多缓存对象的个数。</li><li><code>readOnly</code>： 是否只读，若配置可读写，则需要对应的实体类能够序列化。</li><li><code>blocking</code>： 若缓存中找不到对应的key，是否会一直blocking，直到有对应的数据进入缓存。</li></ul><p><code>cache-ref</code>代表引用别的命名空间的Cache配置，两个命名空间的操作使用的是同一个Cache。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">cache-ref</span> <span class="attr">namespace</span>=<span class="string">"mapper.StudentMapper"</span>/&gt;</span></span><br></pre></td></tr></table></figure><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><ol><li>MyBatis的二级缓存相对于一级缓存来说，实现了<code>SqlSession</code>之间缓存数据的共享，同时粒度更加的细，能够到<code>namespace</code>级别，通过Cache接口实现类不同的组合，对Cache的可控性也更强。</li><li>MyBatis在多表查询时，极大可能会出现脏数据，有设计上的缺陷，安全使用二级缓存的条件比较苛刻。</li><li>在分布式环境下，由于默认的MyBatis Cache实现都是基于本地的，分布式环境下必然会出现读取到脏数据，需要使用集中式缓存将MyBatis的Cache接口实现，有一定的开发成本，直接使用Redis、Memcached等分布式缓存可能成本更低，安全性也更高。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一级缓存&quot;&gt;&lt;a href=&quot;#一级缓存&quot; class=&quot;headerlink&quot; title=&quot;一级缓存&quot;&gt;&lt;/a&gt;一级缓存&lt;/h2&gt;&lt;p&gt;在应用运行过程中，我们有可能在一次数据库会话中，执行多次查询条件完全相同的SQL，MyBatis提供了一级缓存的方案优化这部
      
    
    </summary>
    
    
      <category term="Mybatis" scheme="http://yoursite.com/tags/Mybatis/"/>
    
  </entry>
  
  <entry>
    <title>SpringAOP</title>
    <link href="http://yoursite.com/2019/08/19/SpringAOP/"/>
    <id>http://yoursite.com/2019/08/19/SpringAOP/</id>
    <published>2019-08-19T06:46:18.000Z</published>
    <updated>2019-08-29T15:51:00.070Z</updated>
    
    <content type="html"><![CDATA[<h2 id="AOP概述"><a href="#AOP概述" class="headerlink" title="AOP概述"></a>AOP概述</h2><p>AOP称为面向切面编程，那我们怎么理解面向切面编程？</p><p>我们学Java面向对象的时候，如果代码重复了怎么办啊？可以分成下面几个步骤：</p><ul><li>抽取成方法</li><li>抽取类</li></ul><p>抽取成类的方式我们称之为：<strong>纵向抽取</strong></p><ul><li>通过继承的方式实现纵向抽取</li></ul><p>但是，我们现在的办法不行：即使抽取成类还是会出现重复的代码，因为这些逻辑(开始、结束、提交事务)<strong>依附在我们业务类的方法逻辑中</strong>！</p><a id="more"></a><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190819150731837.png" alt="image-20190819150731837"></p><p>现在纵向抽取的方式不行了，AOP的理念：就是将<strong>分散在各个业务逻辑代码中相同的代码通过横向切割的方式</strong>抽取到一个独立的模块中！</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190819150839531.png" alt="image-20190819150839531"></p><p>上面的图也很清晰了，将重复性的逻辑代码横切出来其实很容易(我们简单可认为就是封装成一个类就好了)，但我们要将这些<strong>被我们横切出来的逻辑代码融合到业务逻辑中</strong>，来完成和之前(没抽取前)一样的功能！这就是AOP首要解决的问题了！</p><h2 id="Spring-AOP原理"><a href="#Spring-AOP原理" class="headerlink" title="Spring AOP原理"></a>Spring AOP原理</h2><p>被我们横切出来的逻辑代码融合到业务逻辑中，来完成和之前(没抽取前)一样的功能</p><p>Spring AOP构建在动态代理基础之上，因此，<strong>Spring对AOP的支持局限于方法拦截</strong>。</p><p>在Java中动态代理有<strong>两种</strong>方式：</p><ul><li><p>JDK动态代理</p></li><li><p>CGLib动态代理</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190819151005879.png" alt="image-20190819151005879"></p></li></ul><p>JDK动态代理是需要实现某个接口了，而我们类未必全部会有接口，于是CGLib代理就有了~~</p><ul><li>CGLib代理其生成的动态代理对象是目标类的子类</li><li>Spring AOP<strong>默认是使用JDK动态代理</strong>，如果代理的类<strong>没有接口则会使用CGLib代理</strong>。</li></ul><p>那么JDK代理和CGLib代理我们该用哪个呢？？在《精通Spring4.x 企业应用开发实战》给出了建议：</p><ul><li>如果是<strong>单例的我们最好使用CGLib代理</strong>，如果是多例的我们最好使用JDK代理</li></ul><p>原因：</p><ul><li>JDK在创建代理对象时的性能要高于CGLib代理，而生成代理对象的运行性能却比CGLib的低。</li><li>如果是单例的代理，推荐使用CGLib</li></ul><p>看到这里我们就应该知道什么是Spring AOP(面向切面编程)了：<strong>将相同逻辑的重复代码横向抽取出来，使用动态代理技术将这些重复代码织入到目标对象方法中，实现和原来一样的功能</strong>。</p><ul><li>这样一来，我们就在<strong>写业务时只关心业务代码</strong>，而不用关心与业务无关的代码</li></ul><h2 id="AOP的术语"><a href="#AOP的术语" class="headerlink" title="AOP的术语"></a>AOP的术语</h2><p><strong>连接点</strong>(Join point)：</p><ul><li><strong>能够被拦截的地方</strong>：Spring AOP是基于动态代理的，所以是方法拦截的。每个成员方法都可以称之为连接点</li></ul><p><strong>切点</strong>(Poincut)：</p><ul><li><strong>具体定位的连接点</strong>：上面也说了，每个方法都可以称之为连接点，我们<strong>具体定位到某一个方法就成为切点</strong>。</li></ul><p><strong>增强/通知</strong>(Advice)：</p><ul><li>表示添加到切点的一段逻辑代码，并定位连接点的方位信息。<ul><li>简单来说就定义了是干什么的，具体是在哪干</li><li>Spring AOP提供了5种Advice类型给我们：前置、后置、返回、异常、环绕给我们使用！</li></ul></li></ul><p><strong>织入</strong>(Weaving)：</p><ul><li>将<code>增强/通知</code>添加到目标类的具体连接点上的过程。</li></ul><p><strong>引入/引介</strong>(Introduction)：</p><ul><li><code>引入/引介</code>允许我们<strong>向现有的类添加新方法或属性</strong>。是一种<strong>特殊</strong>的增强！</li></ul><p><strong>切面</strong>(Aspect)：</p><ul><li>切面由切点和<code>增强/通知</code>组成，它既包括了横切逻辑的定义、也包括了连接点的定义。</li></ul><p>在《Spring 实战 (第4版)》给出的</p><p>通知/增强包含了需要用于多个应用对象的横切行为；连接点是程序执行过程中能够应用通知的所有点；切点定义了通知/增强被应用的具体位置。其中关键的是切点定义了哪些连接点会得到通知/增强。</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190819152914835.png" alt="image-20190819152914835"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;AOP概述&quot;&gt;&lt;a href=&quot;#AOP概述&quot; class=&quot;headerlink&quot; title=&quot;AOP概述&quot;&gt;&lt;/a&gt;AOP概述&lt;/h2&gt;&lt;p&gt;AOP称为面向切面编程，那我们怎么理解面向切面编程？&lt;/p&gt;
&lt;p&gt;我们学Java面向对象的时候，如果代码重复了怎么办啊？可以分成下面几个步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;抽取成方法&lt;/li&gt;
&lt;li&gt;抽取类&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;抽取成类的方式我们称之为：&lt;strong&gt;纵向抽取&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过继承的方式实现纵向抽取&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是，我们现在的办法不行：即使抽取成类还是会出现重复的代码，因为这些逻辑(开始、结束、提交事务)&lt;strong&gt;依附在我们业务类的方法逻辑中&lt;/strong&gt;！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Spring" scheme="http://yoursite.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>SpringIOC</title>
    <link href="http://yoursite.com/2019/08/18/SpringIOC/"/>
    <id>http://yoursite.com/2019/08/18/SpringIOC/</id>
    <published>2019-08-18T02:46:18.000Z</published>
    <updated>2019-08-29T15:51:00.071Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>IoC(Inversion of Control)控制反转，包含了两个方面：一、控制。二、反转</p></blockquote><p>我们可以简单认为：</p><ul><li>控制指的是：<strong>当前对象对内部成员的控制权</strong>。</li><li>反转指的是：这种控制权<strong>不由当前对象管理</strong>了，由其他(类,第三方容器)来管理。</li></ul><p>使用IOC的好处：</p><ol><li>不用自己组装，拿来就用。</li><li>享受单例的好处，效率高，不浪费空间。</li><li>便于单元测试，方便切换mock组件。</li><li>便于进行AOP操作，对于使用者是透明的。</li><li>统一配置，便于修改</li></ol><a id="more"></a><h2 id="IOC原理"><a href="#IOC原理" class="headerlink" title="IOC原理"></a>IOC原理</h2><h3 id="IOC容器其实就是一个大工厂，它用来管理我们所有的对象以及依赖关系"><a href="#IOC容器其实就是一个大工厂，它用来管理我们所有的对象以及依赖关系" class="headerlink" title="IOC容器其实就是一个大工厂，它用来管理我们所有的对象以及依赖关系"></a>IOC容器其实就是一个大工厂，它用来管理我们所有的对象以及依赖关系</h3><ul><li>原理就是通过Java的<strong>反射技术</strong>来实现的！通过反射我们可以获取类的所有信息(成员变量、类名等等等)！</li><li>再通过配置文件(xml)或者注解来<strong>描述</strong>类与类之间的关系</li><li>我们就可以通过这些配置信息和反射技术来<strong>构建</strong>出对应的对象和依赖关系</li></ul><h3 id="Spring-IOC容器是怎么实现对象的创建和依赖的："><a href="#Spring-IOC容器是怎么实现对象的创建和依赖的：" class="headerlink" title="Spring IOC容器是怎么实现对象的创建和依赖的："></a>Spring IOC容器是怎么实现对象的创建和依赖的：</h3><ol><li>根据Bean配置信息在容器内部创建Bean定义注册表</li><li>根据注册表加载、实例化bean、建立Bean与Bean之间的依赖关系</li><li>将这些准备就绪的Bean放到Map缓存池中，等待应用程序调用</li></ol><h3 id="Spring容器-Bean工厂-可简单分成两种："><a href="#Spring容器-Bean工厂-可简单分成两种：" class="headerlink" title="Spring容器(Bean工厂)可简单分成两种："></a>Spring容器(Bean工厂)可简单分成两种：</h3><ul><li><p>BeanFactory</p></li><li><ul><li>这是最基础、面向Spring的</li></ul></li><li><p>ApplicationContext</p></li><li><ul><li>这是在BeanFactory基础之上，面向使用Spring框架的开发者。提供了一系列的功能！</li></ul></li></ul><p>几乎所有的应用场合<strong>都是</strong>使用ApplicationContext！</p><p>简要总结：</p><ul><li>BeanDefinitionReader<strong>读取Resource所指向的配置文件资源</strong>，然后解析配置文件。配置文件中每一个<code>&lt;bean&gt;</code>解析成一个<strong>BeanDefinition对象</strong>，并<strong>保存</strong>到BeanDefinitionRegistry中；</li><li>容器扫描BeanDefinitionRegistry中的BeanDefinition；调用InstantiationStrategy<strong>进行Bean实例化的工作</strong>；使用<strong>BeanWrapper完成Bean属性的设置</strong>工作；</li><li>单例Bean缓存池：Spring 在DefaultSingletonBeanRegistry类中提供了一个用于缓存单实例 Bean 的<strong>缓存器</strong>，它是一个用HashMap实现的缓存器，单实例的Bean<strong>以beanName为键保存在这个HashMap</strong>中。</li></ul><h3 id="依赖注入方式"><a href="#依赖注入方式" class="headerlink" title="依赖注入方式"></a>依赖注入方式</h3><p>依赖注入的方式有3种方式：</p><ul><li><strong>属性注入</strong>–&gt;通过<code>setter()</code>方法注入</li><li>构造函数注入</li><li>工厂方法注入</li></ul><h3 id="一个接口两个实现类，怎么在调用的时候优先调用某个实现类呢？"><a href="#一个接口两个实现类，怎么在调用的时候优先调用某个实现类呢？" class="headerlink" title="一个接口两个实现类，怎么在调用的时候优先调用某个实现类呢？"></a>一个接口两个实现类，怎么在调用的时候优先调用某个实现类呢？</h3><ul><li><p>使用<code>@Primary</code>注解设置为<strong>首选</strong>的注入Bean</p></li><li><p>使用<code>@Qualifier</code>注解设置<strong>特定名称的Bean</strong>来限定注入！</p></li><li><ul><li>也可以使用自定义的注解来标识  </li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;IoC(Inversion of Control)控制反转，包含了两个方面：一、控制。二、反转&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;我们可以简单认为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;控制指的是：&lt;strong&gt;当前对象对内部成员的控制权&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;反转指的是：这种控制权&lt;strong&gt;不由当前对象管理&lt;/strong&gt;了，由其他(类,第三方容器)来管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用IOC的好处：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不用自己组装，拿来就用。&lt;/li&gt;
&lt;li&gt;享受单例的好处，效率高，不浪费空间。&lt;/li&gt;
&lt;li&gt;便于单元测试，方便切换mock组件。&lt;/li&gt;
&lt;li&gt;便于进行AOP操作，对于使用者是透明的。&lt;/li&gt;
&lt;li&gt;统一配置，便于修改&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Spring" scheme="http://yoursite.com/tags/Spring/"/>
    
  </entry>
  
  <entry>
    <title>LinkedListMap介绍</title>
    <link href="http://yoursite.com/2019/08/16/LinkedListMap%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yoursite.com/2019/08/16/LinkedListMap介绍/</id>
    <published>2019-08-16T08:32:13.000Z</published>
    <updated>2019-08-29T15:51:00.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>LinkedHashMap继承于HashMap</p><h2 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h2><p>HashMap是无序的，当我们希望有顺序地去存储key-value时，就需要使用LinkedHashMap了。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, String&gt; hashMap = <span class="keyword">new</span> HashMap&lt;String, String&gt;();</span><br><span class="line">      hashMap.put(<span class="string">"name5"</span>, <span class="string">"value5"</span>);</span><br><span class="line">      hashMap.put(<span class="string">"name6"</span>, <span class="string">"value6"</span>);</span><br><span class="line">      hashMap.put(<span class="string">"name7"</span>, <span class="string">"value7"</span>);</span><br><span class="line">      Set&lt;Map.Entry&lt;String, String&gt;&gt; set = hashMap.entrySet();</span><br><span class="line">      Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = set.iterator();</span><br><span class="line">      <span class="keyword">while</span>(iterator.hasNext()) &#123;</span><br><span class="line">          Map.Entry entry = iterator.next();</span><br><span class="line">          String key = (String) entry.getKey();</span><br><span class="line">          String value = (String) entry.getValue();</span><br><span class="line">          System.out.println(<span class="string">"key:"</span> + key + <span class="string">",value:"</span> + value);</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><p>输出结果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">key:name6,value:value6</span><br><span class="line">key:name5,value:value5</span><br><span class="line">key:name7,value:value7</span><br></pre></td></tr></table></figure><p>同样的数据，我们再试试LinkedHashMap</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;String, String&gt; hashMap = <span class="keyword">new</span> LinkedHashMap&lt;&gt;();</span><br><span class="line">        hashMap.put(<span class="string">"name5"</span>, <span class="string">"value5"</span>);</span><br><span class="line">        hashMap.put(<span class="string">"name6"</span>, <span class="string">"value6"</span>);</span><br><span class="line">        hashMap.put(<span class="string">"name7"</span>, <span class="string">"value7"</span>);</span><br><span class="line">        Set&lt;Map.Entry&lt;String, String&gt;&gt; set = hashMap.entrySet();</span><br><span class="line">        Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iterator = set.iterator();</span><br><span class="line">        <span class="keyword">while</span>(iterator.hasNext()) &#123;</span><br><span class="line">            Map.Entry entry = iterator.next();</span><br><span class="line">            String key = (String) entry.getKey();</span><br><span class="line">            String value = (String) entry.getValue();</span><br><span class="line">            System.out.println(<span class="string">"key:"</span> + key + <span class="string">",value:"</span> + value);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><p>输出结果</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">key:name5,value:value5</span><br><span class="line">key:name6,value:value6</span><br><span class="line">key:name7,value:value7</span><br></pre></td></tr></table></figure><p>LinkedHashMap是有序的，且默认为插入顺序。</p><p>LinkedHashMap空参的构造方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedHashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 调用HashMap的构造方法</span></span><br><span class="line">        <span class="keyword">super</span>();</span><br><span class="line">        <span class="comment">// 这里是指是否基于访问排序，默认为false</span></span><br><span class="line">        accessOrder = <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>这里accessOrder设置为false，表示不是访问顺序而是插入顺序存储的，这也是默认值，表示LinkedHashMap中存储的顺序是按照调用put方法插入的顺序进行排序的。LinkedHashMap也提供了可以设置accessOrder的构造方法。</p><p>在HashMap的构造函数中，调用了init方法，而在HashMap中init方法是空实现，但LinkedHashMap重写了该方法，所以在LinkedHashMap的构造方法里，调用了自身的init方法，init的重写实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Called by superclass constructors and pseudoconstructors (clone,</span></span><br><span class="line"><span class="comment">    * readObject) before any entries are inserted into the map.  Initializes</span></span><br><span class="line"><span class="comment">    * the chain.</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="comment">// 创建了一个hash=-1，key、value、next都为null的Entry</span></span><br><span class="line">       header = <span class="keyword">new</span> Entry&lt;&gt;(-<span class="number">1</span>, <span class="keyword">null</span>, <span class="keyword">null</span>, <span class="keyword">null</span>);</span><br><span class="line">       <span class="comment">// 让创建的Entry的before和after都指向自身，注意after不是之前提到的next</span></span><br><span class="line">       <span class="comment">// 其实就是创建了一个只有头部节点的双向链表</span></span><br><span class="line">       header.before = header.after = header;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>LinkedHashMap有自己的静态内部类Entry，它继承了HashMap.Node，定义如下:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">HashMap</span>.<span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        Entry&lt;K,V&gt; before, after;</span><br><span class="line">        Entry(<span class="keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">            <span class="keyword">super</span>(hash, key, value, next);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>所以LinkedHashMap构造函数，主要就是调用HashMap构造函数初始化了一个Entry[] table，然后调用自身的init初始化了一个只有头结点的双向链表。</p><p>总结</p><p>LinkedHashMap 是继承于HashMap，是基于HashMap和双向链表来实现的。</p><p>HashMap无序；LinkedHashMap有序，可分为插入顺序和访问顺序两种。如果是访问顺序，那put和get操作已存在的Entry时，都会把Entry移动到双向链表的表尾(其实是先删除再插入)。</p><p>LinkedHashMap存取数据，还是跟HashMap一样使用的Entry[]的方式，双向链表只是为了保证顺序。</p><p>LinkedHashMap是线程不安全的。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;LinkedHashMap继承于HashMap&lt;/p&gt;
&lt;h2 id=&quot;应用场景&quot;&gt;&lt;a href=&quot;#应用场景&quot; class=&quot;heade
      
    
    </summary>
    
    
      <category term="Java容器" scheme="http://yoursite.com/tags/Java%E5%AE%B9%E5%99%A8/"/>
    
  </entry>
  
  <entry>
    <title>并发下是先操作数据库还是先操作缓存</title>
    <link href="http://yoursite.com/2019/08/15/%E5%B9%B6%E5%8F%91%E4%B8%8B%E6%98%AF%E5%85%88%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E5%85%88%E6%93%8D%E4%BD%9C%E7%BC%93%E5%AD%98/"/>
    <id>http://yoursite.com/2019/08/15/并发下是先操作数据库还是先操作缓存/</id>
    <published>2019-08-15T03:54:49.000Z</published>
    <updated>2019-08-29T15:51:00.089Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>分布式锁</title>
    <link href="http://yoursite.com/2019/08/13/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://yoursite.com/2019/08/13/分布式锁/</id>
    <published>2019-08-13T09:44:19.000Z</published>
    <updated>2019-08-29T15:51:00.081Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h1><p>在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。</p><p>阻塞锁通常使用互斥量来实现：</p><ul><li>互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态；</li><li>互斥量为 1 表示未锁定状态。</li></ul><p>1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。</p><a id="more"></a><h2 id="数据库的唯一索引"><a href="#数据库的唯一索引" class="headerlink" title="数据库的唯一索引"></a>数据库的唯一索引</h2><p>获得锁时向表中插入一条记录，释放锁时删除这条记录。唯一索引可以保证该记录只被插入一次，那么就可以用这个记录是否存在来判断是否存于锁定状态。</p><p>存在以下几个问题：</p><ul><li>锁没有失效时间，解锁失败的话其它进程无法再获得该锁。</li><li>只能是非阻塞锁，插入失败直接就报错了，无法重试。</li><li>不可重入，已经获得锁的进程也必须重新获取锁。</li></ul><h2 id="Redis-的-SETNX-指令"><a href="#Redis-的-SETNX-指令" class="headerlink" title="Redis 的 SETNX 指令"></a>Redis 的 SETNX 指令</h2><p>使用 SETNX（set if not exist）指令插入一个键值对，如果 Key 已经存在，那么会返回 False，否则插入成功并返回 True。</p><p>SETNX 指令和数据库的唯一索引类似，保证了只存在一个 Key 的键值对，那么可以用一个 Key 的键值对是否存在来判断是否存于锁定状态。</p><p>EXPIRE 指令可以为一个键值对设置一个过期时间，从而避免了数据库唯一索引实现方式中释放锁失败的问题。</p><h2 id="Redis-的-RedLock-算法"><a href="#Redis-的-RedLock-算法" class="headerlink" title="Redis 的 RedLock 算法"></a>Redis 的 RedLock 算法</h2><p>使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时仍然可用。</p><ul><li>尝试从 N 个互相独立 Redis 实例获取锁；</li><li>计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N / 2 + 1）实例上获取了锁，那么就认为锁获取成功了；</li><li>如果锁获取失败，就到每个实例上释放锁。</li></ul><h2 id="Zookeeper-的有序节点"><a href="#Zookeeper-的有序节点" class="headerlink" title="Zookeeper 的有序节点"></a>Zookeeper 的有序节点</h2><h3 id="1-Zookeeper-抽象模型"><a href="#1-Zookeeper-抽象模型" class="headerlink" title="1. Zookeeper 抽象模型"></a>1. Zookeeper 抽象模型</h3><p>Zookeeper 提供了一种树形结构的命名空间，/app1/p_1 节点的父节点为 /app1。</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/WX20190813-203526@2x.png" alt></p><h3 id="2-节点类型"><a href="#2-节点类型" class="headerlink" title="2. 节点类型"></a>2. 节点类型</h3><ul><li>永久节点：不会因为会话结束或者超时而消失；</li><li>临时节点：如果会话结束或者超时就会消失；</li><li>有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-0000000000，它的下一个有序节点则为 /lock/node-0000000001，以此类推。</li></ul><h3 id="3-监听器"><a href="#3-监听器" class="headerlink" title="3. 监听器"></a>3. 监听器</h3><p>为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。</p><h3 id="4-分布式锁实现"><a href="#4-分布式锁实现" class="headerlink" title="4. 分布式锁实现"></a>4. 分布式锁实现</h3><ul><li>创建一个锁目录 /lock；</li><li>当一个客户端需要获取锁时，在 /lock 下创建临时的且有序的子节点；</li><li>客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节点，如果是则认为获得锁；否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获得锁；</li><li>执行业务代码，完成后，删除对应的子节点。</li></ul><h3 id="5-会话超时"><a href="#5-会话超时" class="headerlink" title="5. 会话超时"></a>5. 会话超时</h3><p>如果一个已经获得锁的会话超时了，因为创建的是临时节点，所以该会话对应的临时节点会被删除，其它会话就可以获得锁了。可以看到，Zookeeper 分布式锁不会出现数据库的唯一索引实现的分布式锁释放锁失败问题。</p><h3 id="6-羊群效应"><a href="#6-羊群效应" class="headerlink" title="6. 羊群效应"></a>6. 羊群效应</h3><p>一个节点未获得锁，只需要监听自己的前一个子节点，这是因为如果监听所有的子节点，那么任意一个子节点状态改变，其它所有子节点都会收到通知（羊群效应），而我们只希望它的后一个子节点收到通知。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;分布式锁&quot;&gt;&lt;a href=&quot;#分布式锁&quot; class=&quot;headerlink&quot; title=&quot;分布式锁&quot;&gt;&lt;/a&gt;分布式锁&lt;/h1&gt;&lt;p&gt;在单机场景下，可以使用语言的内置锁来实现进程同步。但是在分布式场景下，需要同步的进程可能位于不同的节点上，那么就需要使用分布式锁。&lt;/p&gt;
&lt;p&gt;阻塞锁通常使用互斥量来实现：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;互斥量为 0 表示有其它进程在使用锁，此时处于锁定状态；&lt;/li&gt;
&lt;li&gt;互斥量为 1 表示未锁定状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;1 和 0 可以用一个整型值表示，也可以用某个数据是否存在表示。&lt;/p&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>再探索引-索引优化</title>
    <link href="http://yoursite.com/2019/08/13/%E5%86%8D%E6%8E%A2%E7%B4%A2%E5%BC%95/"/>
    <id>http://yoursite.com/2019/08/13/再探索引/</id>
    <published>2019-08-12T16:41:13.000Z</published>
    <updated>2019-08-29T15:51:00.081Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-独立的列"><a href="#1-独立的列" class="headerlink" title="1. 独立的列"></a>1. 独立的列</h3><p>在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。</p><p>例如下面的查询不能使用 actor_id 列的索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> actor_id <span class="keyword">FROM</span> sakila.actor <span class="keyword">WHERE</span> actor_id + <span class="number">1</span> = <span class="number">5</span>;</span><br></pre></td></tr></table></figure><h3 id="2-多列索引"><a href="#2-多列索引" class="headerlink" title="2. 多列索引"></a>2. 多列索引</h3><p>在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT film_id, actor_ id FROM sakila.film_actor WHERE actor_id = 1 AND film_id = 1;</span><br></pre></td></tr></table></figure><h3 id="3-索引列的顺序"><a href="#3-索引列的顺序" class="headerlink" title="3. 索引列的顺序"></a>3. 索引列的顺序</h3><p>让选择性最强的索引列放在前面。</p><p>索引的选择性是指：不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，每个记录的区分度越高，查询效率也越高。</p><p>例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> staff_id)/<span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> staff_id_selectivity,</span><br><span class="line"><span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> customer_id)/<span class="keyword">COUNT</span>(*) <span class="keyword">AS</span> customer_id_selectivity,</span><br><span class="line"><span class="keyword">COUNT</span>(*)</span><br><span class="line"><span class="keyword">FROM</span> payment;</span><br></pre></td></tr></table></figure><h3 id="4-前缀索引"><a href="#4-前缀索引" class="headerlink" title="4. 前缀索引"></a>4. 前缀索引</h3><p>对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。</p><p>前缀长度的选取需要根据索引选择性来确定。</p><h3 id="5-覆盖索引"><a href="#5-覆盖索引" class="headerlink" title="5. 覆盖索引"></a>5. 覆盖索引</h3><p>索引包含所有需要查询的字段的值。</p><p>具有以下优点：</p><ul><li>索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。</li><li>一些存储引擎（例如 MyISAM）在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用（通常比较费时）。</li><li>对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。</li></ul><h2 id="索引的优点"><a href="#索引的优点" class="headerlink" title="索引的优点"></a>索引的优点</h2><ul><li>大大减少了服务器需要扫描的数据行数。</li><li>帮助服务器避免进行排序和分组，以及避免创建临时表（B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，不需要排序和分组，也就不需要创建临时表）。</li><li>将随机 I/O 变为顺序 I/O（B+Tree 索引是有序的，会将相邻的数据都存储在一起）。</li></ul><h2 id="索引的使用条件"><a href="#索引的使用条件" class="headerlink" title="索引的使用条件"></a>索引的使用条件</h2><ul><li>对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效；</li><li>对于中到大型的表，索引就非常有效；</li><li>但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;1-独立的列&quot;&gt;&lt;a href=&quot;#1-独立的列&quot; class=&quot;headerlink&quot; title=&quot;1. 独立的列&quot;&gt;&lt;/a&gt;1. 独立的列&lt;/h3&gt;&lt;p&gt;在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。&lt;/p&gt;
&lt;p&gt;例如下面
      
    
    </summary>
    
    
      <category term="mysql" scheme="http://yoursite.com/tags/mysql/"/>
    
  </entry>
  
  <entry>
    <title>关于CMS的Young GC</title>
    <link href="http://yoursite.com/2019/08/12/%E5%85%B3%E4%BA%8ECMS%E7%9A%84Young-GC/"/>
    <id>http://yoursite.com/2019/08/12/关于CMS的Young-GC/</id>
    <published>2019-08-12T06:16:02.000Z</published>
    <updated>2019-08-29T15:51:00.078Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CMS-收集器"><a href="#CMS-收集器" class="headerlink" title="CMS 收集器"></a>CMS 收集器</h2><p>​    CMS 收集器是一种最短回收时间为目标的收集器。在重视服务的相应速度，希望系统停顿时间最短，以给用户最好的体验</p><p>​    CMS 收集器，实现的算法是标记-清除算法，整个过程分为：</p><ul><li>初始标记</li><li>并发标记</li><li>重新标记</li><li>并发清除</li></ul><p>其中初始标记和重新标记需要 STW</p><a id="more"></a><h2 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h2><p>​    首先初始标记阶段找出 GC Root 所能直接关联的对象，速度很快，如 Java 栈中引用的对象、方法区中静态变量应用的对象和系统词典中应用的对象并标记，找出老年代对象在 eden 区有引用关系的对象并标记，最后把这些标记的对象复制到 to，在复制过程中还要判断活跃的对象 GC 年领是否已经达到了阈值，如果已经达到阈值，就直接晋升到老年代，YGC 结束之后将 from 和 to 的引用互换。其中大对象直接晋升到老年代，避免了在 eden 区、form、to 之间的复制。在发生 YGC 前，虚拟机会检查老年代最大的连续空间是否大于新生代所有对象的总空间，如果条件成立，那么进行 YGC 是安全的，如果不成立，检查虚拟机是允许担保失败，如果允许会检查老年代最大的连续空间是否大于历次晋升到老年代对象的平均大小或者新生代对象总大小，如果大于则进行 YGC ，如果条件不成立，或者虚拟机不允许空间担保失败，则进行一次 Full GC。</p><h2 id="CMS-收集器缺点"><a href="#CMS-收集器缺点" class="headerlink" title="CMS 收集器缺点"></a>CMS 收集器缺点</h2><ul><li>CMS 收集器对CPU 资源非常敏感</li><li>CMS 收收集器无法处理浮动垃圾，可能出现 “ Concureent Mode Failure” 失败而导致另一次 Full GC 的产生。要是 CMS 在运行期间预留的内存无法满足程序需要，就会出现一次 “ Concureent Mode Failure” ,这个时候虚拟机临时启动 Serial Old 收集器重新来进行老年代的垃圾收集，这样停顿时间就很长了。</li><li>大量空间碎片，空间碎片过多的话会给分配大对象带来麻烦，即使老年代有很大的空间但是无法找到足够大的连续空间来分配当前对象，不得不提前触发一次 Full GC, 为了解决这个问题，CMS 提供了内存碎片整理的参数来设置，或者我进行几次不带碎片整理的 Full GC 之后，随后带一次碎片整理的 Full GC。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;CMS-收集器&quot;&gt;&lt;a href=&quot;#CMS-收集器&quot; class=&quot;headerlink&quot; title=&quot;CMS 收集器&quot;&gt;&lt;/a&gt;CMS 收集器&lt;/h2&gt;&lt;p&gt;​    CMS 收集器是一种最短回收时间为目标的收集器。在重视服务的相应速度，希望系统停顿时间最短，以给用户最好的体验&lt;/p&gt;
&lt;p&gt;​    CMS 收集器，实现的算法是标记-清除算法，整个过程分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;初始标记&lt;/li&gt;
&lt;li&gt;并发标记&lt;/li&gt;
&lt;li&gt;重新标记&lt;/li&gt;
&lt;li&gt;并发清除&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其中初始标记和重新标记需要 STW&lt;/p&gt;
    
    </summary>
    
    
      <category term="JVM" scheme="http://yoursite.com/tags/JVM/"/>
    
  </entry>
  
  <entry>
    <title>分布式事务</title>
    <link href="http://yoursite.com/2019/08/11/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"/>
    <id>http://yoursite.com/2019/08/11/分布式事务/</id>
    <published>2019-08-11T14:12:15.000Z</published>
    <updated>2019-08-29T15:51:00.082Z</updated>
    
    <content type="html"><![CDATA[<h1 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h1><p>指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。</p><p>例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。</p><p>分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了<strong>保证不同数据库</strong>的数据一致性。</p><a id="more"></a><h2 id="分布式事务产生的原因"><a href="#分布式事务产生的原因" class="headerlink" title="分布式事务产生的原因"></a>分布式事务产生的原因</h2><p>从上面本地事务来看，我们可以看为两块，一个是service产生多个节点，另一个是resource产生多个节点。</p><h3 id="service多个节点"><a href="#service多个节点" class="headerlink" title="service多个节点"></a>service多个节点</h3><p>随着互联网快速发展，微服务，SOA等服务架构模式正在被大规模的使用，举个简单的例子，一个公司之内，用户的资产可能分为好多个部分，比如余额，积分，优惠券等等。在公司内部有可能积分功能由一个微服务团队维护，优惠券又是另外的团队维护</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190822165007299.png" alt="image-20190822165007299"></p><p>这样的话就无法保证积分扣减了之后，优惠券能否扣减成功。</p><h3 id="resource多个节点"><a href="#resource多个节点" class="headerlink" title="resource多个节点"></a>resource多个节点</h3><p>同样的，互联网发展得太快了，我们的Mysql一般来说装千万级的数据就得进行分库分表，对于一个支付宝的转账业务来说，你给的朋友转钱，有可能你的数据库是在北京，而你的朋友的钱是存在上海，所以我们依然无法保证他们能同时成功。</p><p><img src="http://pw5y8kqa5.bkt.clouddn.com/image-20190822165046009.png" alt="image-20190822165046009"></p><h2 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h2><p>两阶段提交（Two-phase Commit，2PC），通过引入协调者（Coordinator）来协调参与者的行为，并最终决定这些参与者是否要真正执行事务。</p><h3 id="1-运行过程"><a href="#1-运行过程" class="headerlink" title="1. 运行过程"></a>1. 运行过程</h3><h4 id="1-1-准备阶段"><a href="#1-1-准备阶段" class="headerlink" title="1.1 准备阶段"></a>1.1 准备阶段</h4><p>协调者询问参与者事务是否执行成功，参与者发回事务执行结果。</p><p><a href="https://camo.githubusercontent.com/0fb5844101fb14358fb16e1acd74604713a9bbf5/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34346433333634332d313030342d343361332d623939612d3464363838613038643061312e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/0fb5844101fb14358fb16e1acd74604713a9bbf5/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34346433333634332d313030342d343361332d623939612d3464363838613038643061312e706e67" alt="img"></a></p><h4 id="1-2-提交阶段"><a href="#1-2-提交阶段" class="headerlink" title="1.2 提交阶段"></a>1.2 提交阶段</h4><p>如果事务在每个参与者上都执行成功，事务协调者发送通知让参与者提交事务；否则，协调者发送通知让参与者回滚事务。</p><p>需要注意的是，在准备阶段，参与者执行了事务，但是还未提交。只有在提交阶段接收到协调者发来的通知后，才进行提交或者回滚。</p><p><a href="https://camo.githubusercontent.com/35c4cbcf56393e07b7e469c671a148f0f4130afe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64326165393933322d653262312d343139312d386565392d6535373366333664333839352e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/35c4cbcf56393e07b7e469c671a148f0f4130afe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64326165393933322d653262312d343139312d386565392d6535373366333664333839352e706e67" alt="img"></a></p><h3 id="2-存在的问题"><a href="#2-存在的问题" class="headerlink" title="2. 存在的问题"></a>2. 存在的问题</h3><h4 id="2-1-同步阻塞"><a href="#2-1-同步阻塞" class="headerlink" title="2.1 同步阻塞"></a>2.1 同步阻塞</h4><p>所有事务参与者在等待其它参与者响应的时候都处于同步阻塞状态，无法进行其它操作。</p><h4 id="2-2-单点问题"><a href="#2-2-单点问题" class="headerlink" title="2.2 单点问题"></a>2.2 单点问题</h4><p>协调者在 2PC 中起到非常大的作用，发生故障将会造成很大影响。特别是在阶段二发生故障，所有参与者会一直等待，无法完成其它操作。</p><h4 id="2-3-数据不一致"><a href="#2-3-数据不一致" class="headerlink" title="2.3 数据不一致"></a>2.3 数据不一致</h4><p>在阶段二，如果协调者只发送了部分 Commit 消息，此时网络发生异常，那么只有部分参与者接收到 Commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。</p><h4 id="2-4-太过保守"><a href="#2-4-太过保守" class="headerlink" title="2.4 太过保守"></a>2.4 太过保守</h4><p>任意一个节点失败就会导致整个事务失败，没有完善的容错机制。</p><h2 id="本地消息表"><a href="#本地消息表" class="headerlink" title="本地消息表"></a>本地消息表</h2><p>本地消息表与业务数据表处于同一个数据库中，这样就能利用本地事务来保证在对这两个表的操作满足事务特性，并且使用了消息队列来保证最终一致性。</p><ol><li>在分布式事务操作的一方完成写业务数据的操作之后向本地消息表发送一个消息，本地事务能保证这个消息一定会被写入本地消息表中。</li><li>之后将本地消息表中的消息转发到消息队列中，如果转发成功则将消息从本地消息表中删除，否则继续重新转发。</li><li>在分布式事务操作的另一方从消息队列中读取一个消息，并执行消息中的操作。</li></ol><p><a href="https://camo.githubusercontent.com/a0b613a1f60db10d1ff1b24810c2ecea4a92d200/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34373633323964342d653265662d346637622d386163392d6135326136663738343630302e706e67" target="_blank" rel="noopener"><img src="https://camo.githubusercontent.com/a0b613a1f60db10d1ff1b24810c2ecea4a92d200/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34373633323964342d653265662d346637622d386163392d6135326136663738343630302e706e67" alt="img"></a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;分布式事务&quot;&gt;&lt;a href=&quot;#分布式事务&quot; class=&quot;headerlink&quot; title=&quot;分布式事务&quot;&gt;&lt;/a&gt;分布式事务&lt;/h1&gt;&lt;p&gt;指事务的操作位于不同的节点上，需要保证事务的 ACID 特性。&lt;/p&gt;
&lt;p&gt;例如在下单场景下，库存和订单如果不在同一个节点上，就涉及分布式事务。&lt;/p&gt;
&lt;p&gt;分布式事务就是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。简单的说，就是一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务器上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败。本质上来说，分布式事务就是为了&lt;strong&gt;保证不同数据库&lt;/strong&gt;的数据一致性。&lt;/p&gt;
    
    </summary>
    
    
      <category term="分布式" scheme="http://yoursite.com/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>CPU缓存一致性协议MESI</title>
    <link href="http://yoursite.com/2019/08/10/MESI/"/>
    <id>http://yoursite.com/2019/08/10/MESI/</id>
    <published>2019-08-10T15:19:17.000Z</published>
    <updated>2019-08-29T15:51:00.068Z</updated>
    
    <content type="html"><![CDATA[<h2 id="CPU高速缓存（Cache-Memory）"><a href="#CPU高速缓存（Cache-Memory）" class="headerlink" title="CPU高速缓存（Cache Memory）"></a>CPU高速缓存（Cache Memory）</h2><h3 id="CPU为何要有高速缓存"><a href="#CPU为何要有高速缓存" class="headerlink" title="CPU为何要有高速缓存"></a>CPU为何要有高速缓存</h3><p>CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。</p><p>在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。</p><blockquote><p><strong>时间局部性（Temporal Locality）</strong>：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。</p></blockquote><p>比如循环、递归、方法的反复调用等。</p><blockquote><p><strong>空间局部性（Spatial Locality）</strong>：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。</p></blockquote><p>比如顺序执行的代码、连续创建的两个对象、数组等。</p><a id="more"></a><h3 id="带有高速缓存的CPU执行计算的流程"><a href="#带有高速缓存的CPU执行计算的流程" class="headerlink" title="带有高速缓存的CPU执行计算的流程"></a>带有高速缓存的CPU执行计算的流程</h3><ol><li>程序以及数据被加载到主内存</li><li>指令和数据被加载到CPU的高速缓存</li><li>CPU执行指令，把结果写到高速缓存</li><li>高速缓存中的数据写回主内存</li></ol><p><img src="/2019/08/10/MESI/WX20190813-233303@2x.png" alt></p><h3 id="目前流行的多级缓存结构"><a href="#目前流行的多级缓存结构" class="headerlink" title="目前流行的多级缓存结构"></a>目前流行的多级缓存结构</h3><p>由于CPU的运算速度超越了1级缓存的数据I\O能力，CPU厂商又引入了多级的缓存结构。</p><p>多级缓存结构</p><p><img src="/2019/08/10/MESI/WX20190813-233623@2x.png" alt></p><h2 id="多核CPU多级缓存一致性协议MESI"><a href="#多核CPU多级缓存一致性协议MESI" class="headerlink" title="多核CPU多级缓存一致性协议MESI"></a>多核CPU多级缓存一致性协议MESI</h2><p>多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。这里就引出了一个一致性的协议MESI。</p><h3 id="MESI协议缓存状态"><a href="#MESI协议缓存状态" class="headerlink" title="MESI协议缓存状态"></a>MESI协议缓存状态</h3><p>MESI 是指4中状态的首字母。每个Cache line有4个状态，可用2个bit表示，它们分别是：</p><blockquote><p><strong>缓存行（Cache line）</strong>:缓存存储数据的单元。</p></blockquote><table><thead><tr><th style="text-align:left">状态</th><th style="text-align:left">描述</th><th style="text-align:left">监听任务</th></tr></thead><tbody><tr><td style="text-align:left">M 修改 (Modified)</td><td style="text-align:left">该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。</td><td style="text-align:left">缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S（共享）状态之前被延迟执行。</td></tr><tr><td style="text-align:left">E 独享、互斥 (Exclusive)</td><td style="text-align:left">该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。</td><td style="text-align:left">缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。</td></tr><tr><td style="text-align:left">S 共享 (Shared)</td><td style="text-align:left">该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。</td><td style="text-align:left">缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。</td></tr><tr><td style="text-align:left">I 无效 (Invalid)</td><td style="text-align:left">该Cache line无效。</td><td style="text-align:left">无</td></tr></tbody></table><p><strong>注意：</strong><br><strong>对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的，而S状态可能是非一致的</strong>。如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其它缓存不会广播他们作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行。</p><p>从上面的意义看来E状态是一种投机性的优化：如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务</p><h3 id="MESI状态转换"><a href="#MESI状态转换" class="headerlink" title="MESI状态转换"></a>MESI状态转换</h3><p><img src="/2019/08/10/MESI/WX20190813-234607@2x.png" alt></p><p>理解该图的前置说明：<br>1.触发事件</p><table><thead><tr><th style="text-align:left">触发事件</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td style="text-align:left">本地读取（Local read）</td><td style="text-align:left">本地cache读取本地cache数据</td></tr><tr><td style="text-align:left">本地写入（Local write）</td><td style="text-align:left">本地cache写入本地cache数据</td></tr><tr><td style="text-align:left">远端读取（Remote read）</td><td style="text-align:left">其他cache读取本地cache数据</td></tr><tr><td style="text-align:left">远端写入（Remote write）</td><td style="text-align:left">其他cache写入本地cache数据</td></tr></tbody></table><p>2.cache分类：<br>前提：所有的cache共同缓存了主内存中的某一条数据。</p><p>本地cache:指当前cpu的cache。<br>触发cache:触发读写事件的cache。<br>其他cache:指既除了以上两种之外的cache。<br>注意：本地的事件触发 本地cache和触发cache为相同。</p><p>上图的切换解释：</p><table><thead><tr><th style="text-align:center">状态</th><th style="text-align:center">触发本地读取</th><th style="text-align:center">触发本地写入</th><th style="text-align:center">触发远端读取</th><th style="text-align:center">触发远端写入</th></tr></thead><tbody><tr><td style="text-align:center"><strong>M状态（修改）</strong></td><td style="text-align:center">本地cache:M  触发cache:M 其他cache:I</td><td style="text-align:center">本地cache:M  触发cache:M 其他cache:I</td><td style="text-align:center">本地cache:M→E→S 触发cache:I→S 其他cache:I→S 同步主内存后修改为E独享,同步触发、其他cache后本地、触发、其他cache修改为S共享</td><td style="text-align:center">本地cache:M→E→S→I 触发cache:I→S→E→M 其他cache:I→S→I 同步和读取一样,同步完成后触发cache改为M，本地、其他cache改为I</td></tr><tr><td style="text-align:center"><strong>E状态（独享）</strong></td><td style="text-align:center">本地cache:E 触发cache:E 其他cache:I</td><td style="text-align:center">本地cache:E→M 触发cache:E→M 其他cache:I 本地cache变更为M,其他cache状态应当是I（无效）</td><td style="text-align:center">本地cache:E→S 触发cache:I→S 其他cache:I→S 当其他cache要读取该数据时，其他、触发、本地cache都被设置为S(共享)</td><td style="text-align:center">本地cache:E→S→I 触发cache:I→S→E→M 其他cache:I→S→I 当触发cache修改本地cache独享数据时时，将本地、触发、其他cache修改为S共享.然后触发cache修改为独享，其他、本地cache修改为I（无效），触发cache再修改为M</td></tr><tr><td style="text-align:center"><strong>S状态(共享)</strong></td><td style="text-align:center">本地cache:S 触发cache:S 其他cache:S</td><td style="text-align:center">本地cache:S→E→M 触发cache:S→E→M 其他cache:S→I  当本地cache修改时，将本地cache修改为E,其他cache修改为I,然后再将本地cache为M状态</td><td style="text-align:center">本地cache:S 触发cache:S 其他cache:S</td><td style="text-align:center">本地cache:S→I 触发cache：S→E→M 其他cache:S→I 当触发cache要修改本地共享数据时，触发cache修改为E（独享）,本地、其他cache修改为I（无效）,触发cache再次修改为M(修改)</td></tr><tr><td style="text-align:center"><strong>I状态（无效）</strong></td><td style="text-align:center">本地cache:I→S或者I→E 触发cache:I→S或者I →E 其他cache:E、M、I→S、I 本地、触发cache将从I无效修改为S共享或者E独享，其他cache将从E、M、I 变为S或者I</td><td style="text-align:center">本地cache:I→S→E→M 触发cache:I→S→E→M 其他cache:M、E、S→S→I</td><td style="text-align:center">既然是本cache是I，其他cache操作与它无关</td><td style="text-align:center">既然是本cache是I，其他cache操作与它无关</td></tr></tbody></table><p>下图示意了，当一个cache line的调整的状态的时候，另外一个cache line 需要调整的状态。</p><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">M</th><th style="text-align:center">E</th><th style="text-align:center">S</th><th style="text-align:center">I</th></tr></thead><tbody><tr><td style="text-align:center"><strong>M</strong></td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center"><strong>E</strong></td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center"><strong>S</strong></td><td style="text-align:center">×</td><td style="text-align:center">×</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr><tr><td style="text-align:center"><strong>I</strong></td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td><td style="text-align:center">√</td></tr></tbody></table><p>举个栗子来说：</p><p>假设cache 1 中有一个变量x = 0的cache line 处于S状态(共享)。<br>那么其他拥有x变量的cache 2、cache 3等x的cache line调整为S状态（共享）或者调整为 I 状态（无效）。</p><h3 id="多核缓存协同操作"><a href="#多核缓存协同操作" class="headerlink" title="多核缓存协同操作"></a>多核缓存协同操作</h3><p>假设有三个CPU A、B、C，对应三个缓存分别是cache a、b、 c。在主内存中定义了x的引用值为0。</p><p><img src="/2019/08/10/MESI/WX20190813-235111@2x.png" alt></p><h4 id="单核读取"><a href="#单核读取" class="headerlink" title="单核读取"></a>单核读取</h4><p>那么执行流程是：<br>CPU A发出了一条指令，从主内存中读取x。<br>从主内存通过bus读取到缓存中（远端读取Remote read）,这是该Cache line修改为E状态（独享）.</p><p><img src="/2019/08/10/MESI/WX20190813-235133@2x.png" alt></p><h4 id="双核读取"><a href="#双核读取" class="headerlink" title="双核读取"></a>双核读取</h4><p>那么执行流程是：<br>CPU A发出了一条指令，从主内存中读取x。<br>CPU A从主内存通过bus读取到 cache a中并将该cache line 设置为E状态。<br>CPU B发出了一条指令，从主内存中读取x。<br>CPU B试图从主内存中读取x时，CPU A检测到了地址冲突。这时CPU A对相关数据做出响应。此时x 存储于cache a和cache b中，x在chche a和cache b中都被设置为S状态(共享)。</p><p><img src="/2019/08/10/MESI/WX20190813-235225@2x.png" alt></p><h4 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h4><p>那么执行流程是：<br>CPU A 计算完成后发指令需要修改x.<br>CPU A 将x设置为M状态（修改）并通知缓存了x的CPU B, CPU B将本地cache b中的x设置为I状态(无效)<br>CPU A 对x进行赋值。</p><p><img src="/2019/08/10/MESI/WX20190813-235306@2x.png" alt></p><h4 id="同步数据"><a href="#同步数据" class="headerlink" title="同步数据"></a>同步数据</h4><p>那么执行流程是：</p><p>CPU B 发出了要读取x的指令。<br>CPU B 通知CPU A,CPU A将修改后的数据同步到主内存时cache a 修改为E（独享）<br>CPU A同步CPU B的x,将cache a和同步后cache b中的x设置为S状态（共享）。</p><p><img src="/2019/08/10/MESI/WX20190813-235340@2x.png" alt></p><h2 id="MESI优化和他们引入的问题"><a href="#MESI优化和他们引入的问题" class="headerlink" title="MESI优化和他们引入的问题"></a>MESI优化和他们引入的问题</h2><p>缓存的一致性消息传递是要时间的，这就使其切换时会产生延迟。当一个缓存被切换状态时其他缓存收到消息完成各自的切换并且发出回应消息这么一长串的时间中CPU都会等待所有缓存响应完成。可能出现的阻塞都会导致各种各样的性能问题和稳定性问题。</p><h3 id="CPU切换状态阻塞解决-存储缓存（Store-Bufferes）"><a href="#CPU切换状态阻塞解决-存储缓存（Store-Bufferes）" class="headerlink" title="CPU切换状态阻塞解决-存储缓存（Store Bufferes）"></a>CPU切换状态阻塞解决-存储缓存（Store Bufferes）</h3><p>比如你需要修改本地缓存中的一条信息，那么你必须将I（无效）状态通知到其他拥有该缓存数据的CPU缓存中，并且等待确认。等待确认的过程会阻塞处理器，这会降低处理器的性能。应为这个等待远远比一个指令的执行时间长的多。</p><h4 id="Store-Bufferes"><a href="#Store-Bufferes" class="headerlink" title="Store Bufferes"></a>Store Bufferes</h4><p>为了避免这种CPU运算能力的浪费，Store Bufferes被引入使用。处理器把它想要写入到主存的值写到缓存，然后继续去处理其他事情。当所有失效确认（Invalidate Acknowledge）都接收到时，数据才会最终被提交。<br>这么做有两个风险</p><h4 id="Store-Bufferes的风险"><a href="#Store-Bufferes的风险" class="headerlink" title="Store Bufferes的风险"></a>Store Bufferes的风险</h4><p>第一、就是处理器会尝试从存储缓存（Store buffer）中读取值，但它还没有进行提交。这个的解决方案称为Store Forwarding，它使得加载的时候，如果存储缓存中存在，则进行返回。<br>第二、保存什么时候会完成，这个并没有任何保证。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">value = <span class="number">3</span>；</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">exeToCPUA</span><span class="params">()</span></span>&#123;</span><br><span class="line">  value = <span class="number">10</span>;</span><br><span class="line">  isFinsh = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">exeToCPUB</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="keyword">if</span>(isFinsh)&#123;</span><br><span class="line">    <span class="comment">//value一定等于10？！</span></span><br><span class="line">    <span class="keyword">assert</span> value == <span class="number">10</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>试想一下开始执行时，CPU A保存着finished在E(独享)状态，而value并没有保存在它的缓存中。（例如，Invalid）。在这种情况下，value会比finished更迟地抛弃存储缓存。完全有可能CPU B读取finished的值为true，而value的值不等于10。</p><p><strong>即isFinsh的赋值在value赋值之前。</strong></p><p>这种在可识别的行为中发生的变化称为重排序（reordings）。注意，这不意味着你的指令的位置被恶意（或者好意）地更改。</p><p>它只是意味着其他的CPU会读到跟程序中写入的顺序不一样的结果。</p><p><del>顺便提一下NIO的设计和Store Bufferes的设计是非常相像的。</del></p><h3 id="硬件内存模型"><a href="#硬件内存模型" class="headerlink" title="硬件内存模型"></a>硬件内存模型</h3><p>执行失效也不是一个简单的操作，它需要处理器去处理。另外，存储缓存（Store Buffers）并不是无穷大的，所以处理器有时需要等待失效确认的返回。这两个操作都会使得性能大幅降低。为了应付这种情况，引入了失效队列。它们的约定如下：</p><ul><li>对于所有的收到的Invalidate请求，Invalidate Acknowlege消息必须立刻发送</li><li>Invalidate并不真正执行，而是被放在一个特殊的队列中，在方便的时候才会去执行。</li><li>处理器不会发送任何消息给所处理的缓存条目，直到它处理Invalidate。</li></ul><p>即便是这样处理器已然不知道什么时候优化是允许的，而什么时候并不允许。<br>干脆处理器将这个任务丢给了写代码的人。这就是内存屏障（Memory Barriers）。</p><blockquote><p><strong>写屏障 Store Memory Barrier(a.k.a. ST, SMB, smp_wmb)是一条告诉处理器在执行这之后的指令之前，应用所有已经在存储缓存（store buffer）中的保存的指令。</strong></p></blockquote><blockquote><p><strong>读屏障Load Memory Barrier (a.k.a. LD, RMB, smp_rmb)是一条告诉处理器在执行任何的加载前，先应用所有已经在失效队列中的失效操作的指令。</strong></p></blockquote><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">executedOnCpu0</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    value = <span class="number">10</span>;</span><br><span class="line">    <span class="comment">//在更新数据之前必须将所有存储缓存（store buffer）中的指令执行完毕。</span></span><br><span class="line">    storeMemoryBarrier();</span><br><span class="line">    finished = <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">executedOnCpu1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(!finished);</span><br><span class="line">    <span class="comment">//在读取之前将所有失效队列中关于该数据的指令执行完毕。</span></span><br><span class="line">    loadMemoryBarrier();</span><br><span class="line">    <span class="keyword">assert</span> value == <span class="number">10</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在确实安全了。完美无暇！</p><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><p>然而，对于程序员来说简直是一个灾难。不想和平台耦合我们要跨平台。Write One,Run Everywhere!<br>幸好java解决了这个问题，至于如何解决的请关注JMM(JavaMemoryMode)与物理内存相爱相杀。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;CPU高速缓存（Cache-Memory）&quot;&gt;&lt;a href=&quot;#CPU高速缓存（Cache-Memory）&quot; class=&quot;headerlink&quot; title=&quot;CPU高速缓存（Cache Memory）&quot;&gt;&lt;/a&gt;CPU高速缓存（Cache Memory）&lt;/h2&gt;&lt;h3 id=&quot;CPU为何要有高速缓存&quot;&gt;&lt;a href=&quot;#CPU为何要有高速缓存&quot; class=&quot;headerlink&quot; title=&quot;CPU为何要有高速缓存&quot;&gt;&lt;/a&gt;CPU为何要有高速缓存&lt;/h3&gt;&lt;p&gt;CPU在摩尔定律的指导下以每18个月翻一番的速度在发展，然而内存和硬盘的发展速度远远不及CPU。这就造成了高性能能的内存和硬盘价格及其昂贵。然而CPU的高度运算需要高速的数据。为了解决这个问题，CPU厂商在CPU中内置了少量的高速缓存以解决I\O速度和CPU运算速度之间的不匹配问题。&lt;/p&gt;
&lt;p&gt;在CPU访问存储设备时，无论是存取数据抑或存取指令，都趋于聚集在一片连续的区域中，这就被称为局部性原理。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;时间局部性（Temporal Locality）&lt;/strong&gt;：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比如循环、递归、方法的反复调用等。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;空间局部性（Spatial Locality）&lt;/strong&gt;：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;比如顺序执行的代码、连续创建的两个对象、数组等。&lt;/p&gt;
    
    </summary>
    
    
      <category term="缓存" scheme="http://yoursite.com/tags/%E7%BC%93%E5%AD%98/"/>
    
  </entry>
  
  <entry>
    <title>redis实现分布式锁</title>
    <link href="http://yoursite.com/2019/08/03/redis%E5%AE%9E%E7%8E%B0%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://yoursite.com/2019/08/03/redis实现分布式锁/</id>
    <published>2019-08-03T13:54:48.000Z</published>
    <updated>2019-08-29T15:51:00.075Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-单机Redis实现分布式锁"><a href="#1-单机Redis实现分布式锁" class="headerlink" title="1.单机Redis实现分布式锁"></a>1.单机Redis实现分布式锁</h2><h3 id="1-1获取锁"><a href="#1-1获取锁" class="headerlink" title="1.1获取锁"></a>1.1获取锁</h3><p>获取锁的过程很简单，客户端向Redis发送命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SET resource_name my_random_value NX PX 30000</span><br></pre></td></tr></table></figure><p><code>my_random_value</code>是由客户端生成的一个随机字符串，它要保证在足够长的一段时间内在所有客户端的所有获取锁的请求中都是唯一的。 NX表示只有当<code>resource_name</code>对应的key值不存在的时候才能SET成功。这保证了只有第一个请求的客户端才能获得锁，而其它客户端在锁被释放之前都无法获得锁。 PX 30000表示这个锁有一个30秒的自动过期时间。</p><h3 id="1-2-释放锁"><a href="#1-2-释放锁" class="headerlink" title="1.2 释放锁"></a>1.2 释放锁</h3><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">"get"</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">"del"</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>之前获取锁的时候生成的<code>my_random_value</code>作为参数传到Lua脚本里面，作为：<code>ARGV[1]</code>,而 <code>resource_name</code>作为<code>KEYS[1]</code>。Lua脚本可以保证操作的原子性。</p><h3 id="1-3-关于单点Redis实现分布式锁的讨论"><a href="#1-3-关于单点Redis实现分布式锁的讨论" class="headerlink" title="1.3 关于单点Redis实现分布式锁的讨论"></a>1.3 关于单点Redis实现分布式锁的讨论</h3><p>网络上有文章说用如下命令获取锁:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SETNX resource_name my_random_value</span><br><span class="line">EXPIRE resource_name 30</span><br></pre></td></tr></table></figure><p>由于这两个命令不是原子的。如果客户端在执行完<code>SETNX</code>后<code>crash</code>了，那么就没有机会执行<code>EXPIRE</code>了，导致它一直持有这个锁，其他的客户端就永远获取不到这个锁了。</p><ul><li>为什么<code>my_random_value</code>要设置成随机值? 保证了一个客户端释放的锁是自己持有的那个锁。如若不然，可能出现锁不安全的情况。</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">客户端1获取锁成功。</span><br><span class="line">客户端1在某个操作上阻塞了很长时间。</span><br><span class="line">过期时间到了，锁自动释放了。</span><br><span class="line">客户端2获取到了对应同一个资源的锁。</span><br><span class="line">客户端1从阻塞中恢复过来，释放掉了客户端2持有的锁。</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><ul><li>用 SETNX获取锁 网上大量文章说用如下命令获取锁：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SETNX lock.foo &lt;current Unix time + lock timeout + 1&gt;</span><br></pre></td></tr></table></figure><p>原文在Redis对SETNX的官网说明，Redis官网文档建议用Set命令来代替，主要原因是SETNX不支持超时时间的设置。</p><p>在开发中 RedisTemplate 为我们封装了 Set 命令</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 如果key不存在，set key and expire key</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> key</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> value</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@param</span> expire</span></span><br><span class="line"><span class="comment">    * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">setAndExpireIfAbsent</span><span class="params">(<span class="keyword">final</span> String key, <span class="keyword">final</span> Serializable value, <span class="keyword">final</span> <span class="keyword">long</span> expire)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">       Boolean result = (Boolean) RedisTemplateHolder.execute(<span class="keyword">new</span> Statement() &#123;</span><br><span class="line">           <span class="meta">@Override</span></span><br><span class="line">           <span class="function"><span class="keyword">public</span> Object <span class="title">prepare</span><span class="params">(RedisTemplate redisTemplate)</span> </span>&#123;</span><br><span class="line">               <span class="keyword">return</span> redisTemplate.execute(<span class="keyword">new</span> RedisCallback&lt;Boolean&gt;() &#123;</span><br><span class="line">                   <span class="meta">@Override</span></span><br><span class="line">                   <span class="function"><span class="keyword">public</span> Boolean <span class="title">doInRedis</span><span class="params">(RedisConnection connection)</span> <span class="keyword">throws</span> DataAccessException </span>&#123;</span><br><span class="line">                       Object obj = connection.execute(<span class="string">"set"</span>, serialize(key), serialize(value), SafeEncoder.encode(<span class="string">"NX"</span>), SafeEncoder.encode(<span class="string">"EX"</span>), Protocol.toByteArray(expire));</span><br><span class="line">                       <span class="keyword">return</span> obj != <span class="keyword">null</span>;</span><br><span class="line">                   &#125;</span><br><span class="line">               &#125;);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;, redisTemplate);</span><br><span class="line"></span><br><span class="line">       <span class="keyword">return</span> result;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><h2 id="2-Redis集群实现分布式锁"><a href="#2-Redis集群实现分布式锁" class="headerlink" title="2.Redis集群实现分布式锁"></a>2.Redis集群实现分布式锁</h2><p>上面的讨论中我们有一个非常重要的假设：Redis是单点的。如果Redis是集群模式，我们考虑如下场景:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">客户端1从Master获取了锁。</span><br><span class="line">Master宕机了，存储锁的key还没有来得及同步到Slave上。</span><br><span class="line">Slave升级为Master。</span><br><span class="line">客户端2从新的Master获取到了对应同一个资源的锁。</span><br><span class="line">客户端1和客户端2同时持有了同一个资源的锁，锁不再具有安全性。</span><br><span class="line">复制代码</span><br></pre></td></tr></table></figure><p>就此问题，Redis作者antirez写了RedLock算法来解决这种问题。</p><h3 id="2-1-RedLock获取锁"><a href="#2-1-RedLock获取锁" class="headerlink" title="2.1 RedLock获取锁"></a>2.1 RedLock获取锁</h3><ul><li>获取当前时间。</li><li>按顺序依次向N个Redis节点执行获取锁的操作。这个获取操作跟前面基于单Redis节点的获取锁的过程相同，包含随机字符串my_random_value，也包含过期时间(比如PX 30000，即锁的有效时间)。为了保证在某个Redis节点不可用的时候算法能够继续运行，这个获取锁的操作还有一个超时时间(time out)，它要远小于锁的有效时间（几十毫秒量级）。客户端在向某个Redis节点获取锁失败以后，应该立即尝试下一个Redis节点。</li><li>计算整个获取锁的过程总共消耗了多长时间，计算方法是用当前时间减去第1步记录的时间。如果客户端从大多数Redis节点（&gt;= N/2+1）成功获取到了锁，并且获取锁总共消耗的时间没有超过锁的有效时间(lock validity time)，那么这时客户端才认为最终获取锁成功；否则，认为最终获取锁失败。</li><li>如果最终获取锁成功了，那么这个锁的有效时间应该重新计算，它等于最初的锁的有效时间减去第3步计算出来的获取锁消耗的时间。</li><li>如果最终获取锁失败了（可能由于获取到锁的Redis节点个数少于N/2+1，或者整个获取锁的过程消耗的时间超过了锁的最初有效时间），那么客户端应该立即向所有Redis节点发起释放锁的操作（即前面介绍的单机Redis Lua脚本释放锁的方法）。</li></ul><h3 id="2-2-RedLock释放锁"><a href="#2-2-RedLock释放锁" class="headerlink" title="2.2 RedLock释放锁"></a>2.2 RedLock释放锁</h3><p>客户端向所有Redis节点发起释放锁的操作，不管这些节点当时在获取锁的时候成功与否。</p><h3 id="2-3-关于RedLock的问题讨论"><a href="#2-3-关于RedLock的问题讨论" class="headerlink" title="2.3 关于RedLock的问题讨论"></a>2.3 关于RedLock的问题讨论</h3><ul><li>如果有节点发生崩溃重启 假设一共有5个Redis节点：A, B, C, D, E。设想发生了如下的事件序列：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">客户端1成功锁住了A, B, C，获取锁成功（但D和E没有锁住）。</span><br><span class="line">节点C崩溃重启了，但客户端1在C上加的锁没有持久化下来，丢失了。</span><br><span class="line">节点C重启后，客户端2锁住了C, D, E，获取锁成功。</span><br><span class="line">客户端1和客户端2同时获得了锁。</span><br></pre></td></tr></table></figure><p>为了应对这一问题，antirez又提出了延迟重启(delayed restarts)的概念。也就是说，一个节点崩溃后，先不立即重启它，而是等待一段时间再重启，这段时间应该大于锁的有效时间(lock validity time)。这样的话，这个节点在重启前所参与的锁都会过期，它在重启后就不会对现有的锁造成影响。</p><ul><li>如果客户端长期阻塞导致锁过期</li></ul><p><img src="/2019/08/03/redis实现分布式锁/Users/maxu/hexo/source/_posts/redis实现分布式锁/WX20190813-220656@2x.png" alt></p><p>解释一下这个时序图，客户端1在获得锁之后发生了很长时间的GC pause，在此期间，它获得的锁过期了，而客户端2获得了锁。当客户端1从GC pause中恢复过来的时候，它不知道自己持有的锁已经过期了，它依然向共享资源（上图中是一个存储服务）发起了写数据请求，而这时锁实际上被客户端2持有，因此两个客户端的写请求就有可能冲突（锁的互斥作用失效了）。</p><p>如何解决这个问题呢?引入了fencing token的概念：</p><p><img src="/2019/08/03/redis实现分布式锁/Users/maxu/hexo/source/_posts/redis实现分布式锁/WX20190813-220732@2x.png" alt="img"></p><p>客户端1先获取到的锁，因此有一个较小的fencing token，等于33，而客户端2后获取到的锁，有一个较大的fencing token，等于34。客户端1从GC pause中恢复过来之后，依然是向存储服务发送访问请求，但是带了fencing token = 33。存储服务发现它之前已经处理过34的请求，所以会拒绝掉这次33的请求。这样就避免了冲突。</p><p>但是其实这已经超出了Redis实现分布式锁的范围，单纯用Redis没有命令来实现生成Token。</p><ul><li>时钟跳跃问题 假设有5个Redis节点A, B, C, D, E。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">客户端1从Redis节点A, B, C成功获取了锁（多数节点）。由于网络问题，与D和E通信失败。</span><br><span class="line">节点C上的时钟发生了向前跳跃，导致它上面维护的锁快速过期。</span><br><span class="line">客户端2从Redis节点C, D, E成功获取了同一个资源的锁（多数节点）。</span><br><span class="line">客户端1和客户端2现在都认为自己持有了锁。</span><br><span class="line">这个问题用Redis实现分布式锁暂时无解。而生产环境这种情况是存在的。</span><br></pre></td></tr></table></figure><p>结论 Redis并不能实现严格意义上的分布式锁。但是这并不意味着上面讨论的方案一无是处。如果你的应用场景为了效率(efficiency)，协调各个客户端避免做重复的工作，即使锁失效了，只是可能把某些操作多做一遍而已，不会产生其它的不良后果。但是如果你的应用场景是为了正确性(correctness)，那么用Redis实现分布式锁并不合适，会存在各种各样的问题，且解决起来就很复杂，为了正确性，需要使用zab、raft共识算法，或者使用带有事务的数据库来实现严格意义上的分布式锁。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;1-单机Redis实现分布式锁&quot;&gt;&lt;a href=&quot;#1-单机Redis实现分布式锁&quot; class=&quot;headerlink&quot; title=&quot;1.单机Redis实现分布式锁&quot;&gt;&lt;/a&gt;1.单机Redis实现分布式锁&lt;/h2&gt;&lt;h3 id=&quot;1-1获取锁&quot;&gt;&lt;a hr
      
    
    </summary>
    
    
      <category term="redis" scheme="http://yoursite.com/tags/redis/"/>
    
  </entry>
  
</feed>
